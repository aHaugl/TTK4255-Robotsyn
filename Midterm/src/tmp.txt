{(array(float64, 1d, A),): '; ModuleID = \'res\'\nsource_filename = "<string>"\ntarget datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"\ntarget triple = "x86_64-pc-windows-msvc"\n\n@"_ZN08NumbaEnv8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE" = common local_unnamed_addr global i8* null\n@.const.picklebuf.1904318645176 = internal constant { i8*, i32, i8* } { i8* getelementptr inbounds ([63 x i8], [63 x i8]* @.const.pickledata.1904318645176, i32 0, i32 0), i32 63, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.const.pickledata.1904318645176.sha1, i32 0, i32 0) }\n@.const.picklebuf.1904360040792 = internal constant { i8*, i32, i8* } { i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.const.pickledata.1904360040792, i32 0, i32 0), i32 61, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.const.pickledata.1904360040792.sha1, i32 0, i32 0) }\n@.const.picklebuf.1904697620984 = internal constant { i8*, i32, i8* } { i8* getelementptr inbounds ([60 x i8], [60 x i8]* @.const.pickledata.1904697620984, i32 0, i32 0), i32 60, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.const.pickledata.1904697620984.sha1, i32 0, i32 0) }\n@.const.picklebuf.1904700834024 = internal constant { i8*, i32, i8* } { i8* getelementptr inbounds ([67 x i8], [67 x i8]* @.const.pickledata.1904700834024, i32 0, i32 0), i32 67, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.const.pickledata.1904700834024.sha1, i32 0, i32 0) }\n@.const.picklebuf.1904699354552 = internal constant { i8*, i32, i8* } { i8* getelementptr inbounds ([131 x i8], [131 x i8]* @.const.pickledata.1904699354552, i32 0, i32 0), i32 131, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.const.pickledata.1904699354552.sha1, i32 0, i32 0) }\n@.const.pickledata.1904699354552 = internal constant [131 x i8] c"\\80\\03cbuiltins\\0AValueError\\0Aq\\00X[\\00\\00\\00array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size.q\\01\\85q\\02N\\87q\\03."\n@.const.pickledata.1904699354552.sha1 = internal constant [20 x i8] c"678\\F0\\A8\\D2\\E2`q\\FBP\\E9\\D2\\1BK\\80\\A9S/\\06"\n@.const.pickledata.1904700834024 = internal constant [67 x i8] c"\\80\\03cbuiltins\\0AValueError\\0Aq\\00X\\1B\\00\\00\\00incompatible sequence shapeq\\01\\85q\\02N\\87q\\03."\n@.const.pickledata.1904700834024.sha1 = internal constant [20 x i8] c"%\\AF\\8E\\C9\\F7\\A1\\80\\8E\\EA\\1C\\A5\\EE\\FB7\\1C\\89X\\BF\\BEx"\n@.const.pickledata.1904697620984 = internal constant [60 x i8] c"\\80\\03cbuiltins\\0AIndexError\\0Aq\\00X\\14\\00\\00\\00getitem out of rangeq\\01\\85q\\02N\\87q\\03."\n@.const.pickledata.1904697620984.sha1 = internal constant [20 x i8] c" \\07\\E5Sb4\\1D\\8C\\B11\\A7l\\9A\\FF\\E8dz\\BD\\A8m"\n@.const.pickledata.1904360040792 = internal constant [61 x i8] c"\\80\\03cbuiltins\\0AMemoryError\\0Aq\\00X\\14\\00\\00\\00cannot allocate listq\\01\\85q\\02N\\87q\\03."\n@.const.pickledata.1904360040792.sha1 = internal constant [20 x i8] c"\\EE\\A2\\80W\\B5\\A3\\E7\\AA\\1C\\AE\\D9C\\9A\\E2\\1E\\E2\\DC\\0Cz\\9B"\n@.const.pickledata.1904318645176 = internal constant [63 x i8] c"\\80\\03cbuiltins\\0AZeroDivisionError\\0Aq\\00X\\10\\00\\00\\00division by zeroq\\01\\85q\\02N\\87q\\03."\n@.const.pickledata.1904318645176.sha1 = internal constant [20 x i8] c"~7\\A9p\\9C\\0A\\80y\\DD\\94\'Y\\83}\\90\\F2\\93+\\AE6"\n@.const.res = internal constant [4 x i8] c"res\\00"\n@PyExc_RuntimeError = external global i8\n@".const.missing Environment: _ZN08NumbaEnv8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE" = internal constant [84 x i8] c"missing Environment: _ZN08NumbaEnv8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE\\00"\n@PyExc_TypeError = external global i8\n@".const.can\'t unbox array from PyObject into native value.  The object maybe of a different type" = internal constant [89 x i8] c"can\'t unbox array from PyObject into native value.  The object maybe of a different type\\00"\n@_Py_NoneStruct = external global i8\n@".const.`env.consts` is NULL in `read_const`" = internal constant [37 x i8] c"`env.consts` is NULL in `read_const`\\00"\n@PyExc_StopIteration = external global i8\n@PyExc_SystemError = external global i8\n@".const.unknown error when calling native function" = internal constant [43 x i8] c"unknown error when calling native function\\00"\n@".const.<numba.core.cpu.CPUContext object at 0x000001BB633C69C8>" = internal constant [57 x i8] c"<numba.core.cpu.CPUContext object at 0x000001BB633C69C8>\\00"\n@".const.unknown error when calling native function.1" = internal constant [43 x i8] c"unknown error when calling native function\\00"\n@"_ZN08NumbaEnv5numba7cpython7numbers14int_power_impl12$3clocals$3e13int_power$245Edx" = common local_unnamed_addr global i8* null\n\ndefine i32 @"_ZN8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE"({ i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* noalias nocapture %retptr, { i8*, i32, i8* }** noalias nocapture %excinfo, i8* nocapture readnone %arg.array.0, i8* nocapture readnone %arg.array.1, i64 %arg.array.2, i64 %arg.array.3, double* %arg.array.4, i64 %arg.array.5.0, i64 %arg.array.6.0) local_unnamed_addr {\nentry:\n  %.53 = ptrtoint double* %arg.array.4 to i64\n  %.56 = load double, double* %arg.array.4, align 8\n  %.94 = add i64 %.53, %arg.array.6.0\n  %.95 = inttoptr i64 %.94 to double*\n  %.96 = load double, double* %.95, align 8\n  %.132 = shl i64 %arg.array.6.0, 1\n  %.134 = add i64 %.132, %.53\n  %.135 = inttoptr i64 %.134 to double*\n  %.136 = load double, double* %.135, align 8\n  %.172 = mul i64 %arg.array.6.0, 3\n  %.174 = add i64 %.172, %.53\n  %.175 = inttoptr i64 %.174 to double*\n  %.176 = load double, double* %.175, align 8\n  %.212 = shl i64 %arg.array.6.0, 2\n  %.214 = add i64 %.212, %.53\n  %.215 = inttoptr i64 %.214 to double*\n  %.216 = load double, double* %.215, align 8\n  %.252 = mul i64 %arg.array.6.0, 5\n  %.254 = add i64 %.252, %.53\n  %.255 = inttoptr i64 %.254 to double*\n  %.256 = load double, double* %.255, align 8\n  %.292 = mul i64 %arg.array.6.0, 6\n  %.294 = add i64 %.292, %.53\n  %.295 = inttoptr i64 %.294 to double*\n  %.296 = load double, double* %.295, align 8\n  %.332 = mul i64 %arg.array.6.0, 7\n  %.334 = add i64 %.332, %.53\n  %.335 = inttoptr i64 %.334 to double*\n  %.336 = load double, double* %.335, align 8\n  %.372 = shl i64 %arg.array.6.0, 3\n  %.374 = add i64 %.372, %.53\n  %.375 = inttoptr i64 %.374 to double*\n  %.376 = load double, double* %.375, align 8\n  %.412 = mul i64 %arg.array.6.0, 9\n  %.414 = add i64 %.412, %.53\n  %.415 = inttoptr i64 %.414 to double*\n  %.416 = load double, double* %.415, align 8\n  %.452 = mul i64 %arg.array.6.0, 10\n  %.454 = add i64 %.452, %.53\n  %.455 = inttoptr i64 %.454 to double*\n  %.456 = load double, double* %.455, align 8\n  %.492 = mul i64 %arg.array.6.0, 11\n  %.494 = add i64 %.492, %.53\n  %.495 = inttoptr i64 %.494 to double*\n  %.496 = load double, double* %.495, align 8\n  %.532 = mul i64 %arg.array.6.0, 12\n  %.534 = add i64 %.532, %.53\n  %.535 = inttoptr i64 %.534 to double*\n  %.536 = load double, double* %.535, align 8\n  %.572 = mul i64 %arg.array.6.0, 13\n  %.574 = add i64 %.572, %.53\n  %.575 = inttoptr i64 %.574 to double*\n  %.576 = load double, double* %.575, align 8\n  %.612 = mul i64 %arg.array.6.0, 14\n  %.614 = add i64 %.612, %.53\n  %.615 = inttoptr i64 %.614 to double*\n  %.616 = load double, double* %.615, align 8\n  %.652 = mul i64 %arg.array.6.0, 15\n  %.654 = add i64 %.652, %.53\n  %.655 = inttoptr i64 %.654 to double*\n  %.656 = load double, double* %.655, align 8\n  %.692 = shl i64 %arg.array.6.0, 4\n  %.694 = add i64 %.692, %.53\n  %.695 = inttoptr i64 %.694 to double*\n  %.696 = load double, double* %.695, align 8\n  %.732 = mul i64 %arg.array.6.0, 17\n  %.734 = add i64 %.732, %.53\n  %.735 = inttoptr i64 %.734 to double*\n  %.736 = load double, double* %.735, align 8\n  %.772 = mul i64 %arg.array.6.0, 18\n  %.774 = add i64 %.772, %.53\n  %.775 = inttoptr i64 %.774 to double*\n  %.776 = load double, double* %.775, align 8\n  %.812 = mul i64 %arg.array.6.0, 19\n  %.814 = add i64 %.812, %.53\n  %.815 = inttoptr i64 %.814 to double*\n  %.816 = load double, double* %.815, align 8\n  %.852 = mul i64 %arg.array.6.0, 20\n  %.854 = add i64 %.852, %.53\n  %.855 = inttoptr i64 %.854 to double*\n  %.856 = load double, double* %.855, align 8\n  %.892 = mul i64 %arg.array.6.0, 21\n  %.894 = add i64 %.892, %.53\n  %.895 = inttoptr i64 %.894 to double*\n  %.896 = load double, double* %.895, align 8\n  %.932 = mul i64 %arg.array.6.0, 22\n  %.934 = add i64 %.932, %.53\n  %.935 = inttoptr i64 %.934 to double*\n  %.936 = load double, double* %.935, align 8\n  %.972 = mul i64 %arg.array.6.0, 23\n  %.974 = add i64 %.972, %.53\n  %.975 = inttoptr i64 %.974 to double*\n  %.976 = load double, double* %.975, align 8\n  %.1023 = tail call double @llvm.sin.f64(double %.96)\n  %.1095 = tail call double @llvm.cos.f64(double %.96)\n  %.1107 = fcmp oeq double %.1095, 0.000000e+00\n  br i1 %.1107, label %for.end.1.if, label %for.end.2, !prof !0\n\nfor.end.1.if:                                     ; preds = %entry\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.2:                                        ; preds = %entry\n  %.376.i = fmul double %.1023, %.1023\n  %reciprocal = fdiv double 1.000000e+00, %.1095\n  %0 = fdiv double %.376.i, %.1095\n  %.1164 = fsub double %reciprocal, %0\n  %.1202 = tail call double @llvm.sin.f64(double %.56)\n  %.376.i15 = fmul double %.1202, %.1202\n  %.1275 = tail call double @llvm.cos.f64(double %.56)\n  %.1287 = fcmp oeq double %.1275, 0.000000e+00\n  br i1 %.1287, label %for.end.4.if, label %for.end.6.endif, !prof !0\n\nfor.end.4.if:                                     ; preds = %for.end.2\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.6.endif:                                  ; preds = %for.end.2\n  %.1174 = fmul double %.1164, 0xC06179F487FCB924\n  %.1250 = fmul double %.376.i15, 0xBFEC989D97BD60F4\n  %.1294 = fdiv double %.1250, %.1275\n  %.1334 = fmul double %.1202, 0x3FDCB549152F342E\n  %.1344 = fsub double %.1294, %.1334\n  %.1391 = fdiv double 0x3FEC989D97BD60F4, %.1275\n  %.1401 = fadd double %.1391, %.1344\n  %.1411 = fmul double %.1174, %.1401\n  %.1588 = fmul double %.1164, 8.073130e+01\n  %.1664 = fmul double %.376.i15, 0x3FDC1EB7D1FA70B4\n  %.1748 = fmul double %.1202, 0x3FEBC45955BE89DD\n  %1 = insertelement <2 x double> <double 0x3FDC1EB7D1FA70B4, double undef>, double %.1664, i32 1\n  %2 = insertelement <2 x double> undef, double %.1275, i32 0\n  %3 = shufflevector <2 x double> %2, <2 x double> undef, <2 x i32> zeroinitializer\n  %4 = fdiv <2 x double> %1, %3\n  %5 = extractelement <2 x double> %4, i32 1\n  %6 = fsub double %.1748, %5\n  %7 = extractelement <2 x double> %4, i32 0\n  %.1815 = fadd double %7, %6\n  %.1825 = fmul double %.1588, %.1815\n  %.1835 = fsub double %.1411, %.1825\n  %.2075 = fmul double %.1401, 4.301880e+01\n  %.2112 = fmul double %.1023, %.2075\n  %.2122 = fsub double %.1835, %.2112\n  %.2362 = fmul double %.1815, 2.484040e+01\n  %.2399 = fmul double %.1023, %.2362\n  %.2409 = fsub double %.2122, %.2399\n  %.2449 = fmul double %.1202, 0x4028ADB676E95786\n  %.2459 = fadd double %.2449, %.2409\n  %.2499 = fmul double %.1023, 0x4030B608D1E57F05\n  %.2509 = fsub double %.2459, %.2499\n  %.2549 = fmul double %.1275, 0x3FE20FE0AC7C17DC\n  %.2559 = fsub double %.2509, %.2549\n  %.2599 = fmul double %.1095, 0x40149145EEA44D96\n  %.2609 = fadd double %.2599, %.2559\n  %.2622 = fadd double %.2609, 0x406EA2E3F5B4B6E1\n  %.2799 = fmul double %.1164, -1.300000e-01\n  %.3036 = fmul double %.2799, %.1815\n  %.3276 = fmul double %.1815, 4.000000e-02\n  %.3313 = fmul double %.1023, %.3276\n  %.3323 = fsub double %.3036, %.3313\n  %.3363 = fmul double %.1202, 0x3F71FF2DF706AE88\n  %.3373 = fadd double %.3363, %.3323\n  %.3413 = fmul double %.1023, 0x3F9EF03E7DCA5163\n  %.3423 = fsub double %.3373, %.3413\n  %.3463 = fmul double %.1275, 0x3F81C557E4F4D31D\n  %.3473 = fsub double %.3423, %.3463\n  %.3513 = fmul double %.1095, 0x3F8309FF12551E5C\n  %.3523 = fadd double %.3513, %.3473\n  %.3536 = fadd double %.3523, 0x3FE943D3A7E01384\n  %.3546 = fcmp oeq double %.3536, 0.000000e+00\n  br i1 %.3546, label %for.end.43.if, label %for.end.43.endif, !prof !0\n\nfor.end.43.if:                                    ; preds = %for.end.6.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.43.endif:                                 ; preds = %for.end.6.endif\n  %.3599 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.3600 = icmp eq i8* %.3599, null\n  br i1 %.3600, label %for.end.43.endif.endif.endif.if, label %for.end.43.endif.endif.endif.endif, !prof !0\n\nfor.end.43.endif.endif.endif.if:                  ; preds = %for.end.43.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.43.endif.endif.endif.endif:               ; preds = %for.end.43.endif\n  %.3553 = fdiv double %.2622, %.3536\n  %.3563 = fsub double %.3553, %.176\n  %.3573 = fmul double %.736, %.3563\n  %.5.i123 = getelementptr i8, i8* %.3599, i64 24\n  %8 = bitcast i8* %.5.i123 to { i64, i64, i8, double }**\n  %.6.i1244171 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %8, align 8\n  %.3612 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i1244171, i64 0, i32 1\n  store i64 1, i64* %.3612, align 8\n  %.6.i1264172 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %8, align 8\n  %.36184248 = bitcast { i64, i64, i8, double }* %.6.i1264172 to i64*\n  store i64 0, i64* %.36184248, align 8\n  %.6.i1284173 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %8, align 8\n  %.3624 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i1284173, i64 0, i32 2\n  store i8 0, i8* %.3624, align 1\n  %.6.i1324175 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %8, align 8\n  %.3637 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i1324175, i64 0, i32 3\n  %9 = bitcast double* %.3637 to i64*\n  store i64 0, i64* %9, align 1\n  %.6.i1363840 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %8, align 8\n  %.36644249 = bitcast { i64, i64, i8, double }* %.6.i1363840 to i64*\n  store i64 1, i64* %.36644249, align 8\n  %.6.i27163842 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %8, align 8\n  %.3677 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i27163842, i64 0, i32 3\n  store double %.3573, double* %.3677, align 8\n  %.3863 = fmul double %.1164, 0x406832B50B0F27BB\n  %.4100 = fmul double %.3863, %.1401\n  %.4277 = fmul double %.1164, 0x405BF20902DE00D2\n  %.4514 = fmul double %.4277, %.1815\n  %.4524 = fadd double %.4100, %.4514\n  %.4811 = fsub double %.4524, %.2112\n  %.5098 = fsub double %.4811, %.2399\n  %.5148 = fadd double %.2449, %.5098\n  %.5188 = fmul double %.1023, 0x4037236EAC78D73A\n  %.5198 = fadd double %.5188, %.5148\n  %.5248 = fsub double %.5198, %.2549\n  %.5298 = fadd double %.2599, %.5248\n  %.5311 = fadd double %.5298, 0x406EA2E3F5B4B6E1\n  %.5488 = fmul double %.1164, 1.800000e-01\n  %.5725 = fmul double %.5488, %.1815\n  %.6012 = fsub double %.5725, %.3313\n  %.6062 = fadd double %.3363, %.6012\n  %.6102 = fmul double %.1023, 0x3FA56B3EF49FC223\n  %.6112 = fadd double %.6102, %.6062\n  %.6162 = fsub double %.6112, %.3463\n  %.6212 = fadd double %.3513, %.6162\n  %.6225 = fadd double %.6212, 0x3FE943D3A7E01384\n  %.6235 = fcmp oeq double %.6225, 0.000000e+00\n  br i1 %.6235, label %for.end.87.if, label %for.end.87.endif, !prof !0\n\nfor.end.87.if:                                    ; preds = %for.end.43.endif.endif.endif.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.87.endif:                                 ; preds = %for.end.43.endif.endif.endif.endif\n  %.6288 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.6289 = icmp eq i8* %.6288, null\n  br i1 %.6289, label %for.end.87.endif.endif.endif.if, label %for.end.87.endif.endif.endif.endif, !prof !0\n\nfor.end.87.endif.endif.endif.if:                  ; preds = %for.end.87.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.87.endif.endif.endif.endif:               ; preds = %for.end.87.endif\n  %.6242 = fdiv double %.5311, %.6225\n  %.6252 = fsub double %.6242, %.216\n  %.6262 = fmul double %.776, %.6252\n  %.5.i2605 = getelementptr i8, i8* %.6288, i64 24\n  %10 = bitcast i8* %.5.i2605 to { i64, i64, i8, double }**\n  %.6.i26064165 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %10, align 8\n  %.6301 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i26064165, i64 0, i32 1\n  store i64 1, i64* %.6301, align 8\n  %.6.i26044166 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %10, align 8\n  %.63074250 = bitcast { i64, i64, i8, double }* %.6.i26044166 to i64*\n  store i64 0, i64* %.63074250, align 8\n  %.6.i26024167 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %10, align 8\n  %.6313 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i26024167, i64 0, i32 2\n  store i8 0, i8* %.6313, align 1\n  %.6.i25984169 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %10, align 8\n  %.6326 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i25984169, i64 0, i32 3\n  %11 = bitcast double* %.6326 to i64*\n  store i64 0, i64* %11, align 1\n  %.6.i25943846 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %10, align 8\n  %.63534251 = bitcast { i64, i64, i8, double }* %.6.i25943846 to i64*\n  store i64 1, i64* %.63534251, align 8\n  %.6.i25903848 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %10, align 8\n  %.6366 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i25903848, i64 0, i32 3\n  store double %.6262, double* %.6366, align 8\n  %.6552 = fmul double %.1164, 0x407CE73BCD35A858\n  %.6789 = fmul double %.6552, %.1401\n  %.6966 = fmul double %.1164, 0x4070B08C7E28240B\n  %.7203 = fmul double %.6966, %.1815\n  %.7213 = fadd double %.6789, %.7203\n  %.7500 = fsub double %.7213, %.2112\n  %.7787 = fsub double %.7500, %.2399\n  %.7837 = fadd double %.2449, %.7787\n  %.7877 = fmul double %.1023, 0x404BA335F8ACC83C\n  %.7887 = fadd double %.7877, %.7837\n  %.7937 = fsub double %.7887, %.2549\n  %.7987 = fadd double %.2599, %.7937\n  %.8000 = fadd double %.7987, 0x406EA2E3F5B4B6E1\n  %.8177 = fmul double %.1164, 4.300000e-01\n  %.8414 = fmul double %.8177, %.1815\n  %.8701 = fsub double %.8414, %.3313\n  %.8751 = fadd double %.3363, %.8701\n  %.8791 = fmul double %.1023, 0x3FB9956EC0A260CB\n  %.8801 = fadd double %.8791, %.8751\n  %.8851 = fsub double %.8801, %.3463\n  %.8901 = fadd double %.3513, %.8851\n  %.8914 = fadd double %.8901, 0x3FE943D3A7E01384\n  %.8924 = fcmp oeq double %.8914, 0.000000e+00\n  br i1 %.8924, label %for.end.131.if, label %for.end.131.endif, !prof !0\n\nfor.end.131.if:                                   ; preds = %for.end.87.endif.endif.endif.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.131.endif:                                ; preds = %for.end.87.endif.endif.endif.endif\n  %.8977 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.8978 = icmp eq i8* %.8977, null\n  br i1 %.8978, label %for.end.131.endif.endif.endif.if, label %for.end.131.endif.endif.endif.endif, !prof !0\n\nfor.end.131.endif.endif.endif.if:                 ; preds = %for.end.131.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.131.endif.endif.endif.endif:              ; preds = %for.end.131.endif\n  %.8931 = fdiv double %.8000, %.8914\n  %.8941 = fsub double %.8931, %.256\n  %.8951 = fmul double %.816, %.8941\n  %.5.i2479 = getelementptr i8, i8* %.8977, i64 24\n  %12 = bitcast i8* %.5.i2479 to { i64, i64, i8, double }**\n  %.6.i24804159 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %12, align 8\n  %.8990 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i24804159, i64 0, i32 1\n  store i64 1, i64* %.8990, align 8\n  %.6.i24784160 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %12, align 8\n  %.89964252 = bitcast { i64, i64, i8, double }* %.6.i24784160 to i64*\n  store i64 0, i64* %.89964252, align 8\n  %.6.i24764161 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %12, align 8\n  %.9002 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i24764161, i64 0, i32 2\n  store i8 0, i8* %.9002, align 1\n  %.6.i24724163 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %12, align 8\n  %.9015 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i24724163, i64 0, i32 3\n  %13 = bitcast double* %.9015 to i64*\n  store i64 0, i64* %13, align 1\n  %.6.i24683852 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %12, align 8\n  %.90424253 = bitcast { i64, i64, i8, double }* %.6.i24683852 to i64*\n  store i64 1, i64* %.90424253, align 8\n  %.6.i24643854 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %12, align 8\n  %.9055 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i24643854, i64 0, i32 3\n  store double %.8951, double* %.9055, align 8\n  %.9331 = fmul double %.1023, %.1401\n  %.9371 = fmul double %.1095, 0x3F8E0DDC2757DD10\n  %.9381 = fadd double %.9371, %.9331\n  %.9416 = tail call double @llvm.sin.f64(double %.136)\n  %.9755 = fmul double %.9381, 4.301880e+01\n  %.9780 = tail call double @llvm.cos.f64(double %.136)\n  %.9792 = fmul double %.9780, %.9755\n  %.10069 = fmul double %.1023, %.1815\n  %.10109 = fmul double %.1095, 0x3FCDBF9E8CA4FF82\n  %.10119 = fsub double %.10069, %.10109\n  %.10503 = fmul double %.10119, 2.484040e+01\n  %.10540 = fmul double %.9780, %.10503\n  %.10727 = fmul double %.1164, 0x4084AB4FF9724745\n  %.10964 = fmul double %.10727, %.1401\n  %.11151 = fmul double %.1164, 0x4077DEBD07C84B5E\n  %.11388 = fmul double %.11151, %.1815\n  %.11508 = fcmp oeq double %.9780, 0.000000e+00\n  br i1 %.11508, label %for.end.175.if, label %for.end.176, !prof !0\n\nfor.end.175.if:                                   ; preds = %for.end.131.endif.endif.endif.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.176:                                      ; preds = %for.end.131.endif.endif.endif.endif\n  %.9391 = fmul double %.9381, 0xC05832B50B0F27BB\n  %.9428 = fmul double %.9416, %.9391\n  %.9802 = fsub double %.9428, %.9792\n  %.10129 = fmul double %.10119, 5.589090e+01\n  %.10166 = fmul double %.9416, %.10129\n  %.10176 = fsub double %.9802, %.10166\n  %.10550 = fsub double %.10176, %.10540\n  %.10974 = fadd double %.10550, %.10964\n  %.11398 = fadd double %.10974, %.11388\n  %.376.i2363 = fmul double %.9416, %.9416\n  %14 = insertelement <2 x double> <double 1.000000e+00, double undef>, double %.376.i2363, i32 1\n  %15 = insertelement <2 x double> undef, double %.9780, i32 0\n  %16 = shufflevector <2 x double> %15, <2 x double> undef, <2 x i32> zeroinitializer\n  %17 = fdiv <2 x double> %14, %16\n  %18 = extractelement <2 x double> %17, i32 0\n  %19 = extractelement <2 x double> %17, i32 1\n  %.11565 = fsub double %18, %19\n  %.11575 = fmul double %.11565, 0x405832B50B0F27BB\n  %.11615 = fmul double %.1202, 0xBFEC989D97BD60F4\n  %.11655 = fmul double %.1275, 0x3FDCB549152F342E\n  %.11665 = fsub double %.11615, %.11655\n  %.11675 = fmul double %.11665, %.11575\n  %.11685 = fsub double %.11398, %.11675\n  %.11862 = fmul double %.11565, 5.589090e+01\n  %.11902 = fmul double %.1202, 0x3FDC1EB7D1FA70B4\n  %.11942 = fmul double %.1275, 0x3FEBC45955BE89DD\n  %20 = fsub double %.11942, %.11902\n  %.11962 = fmul double %20, %.11862\n  %.12075 = fmul double %.11665, 4.301880e+01\n  %.12112 = fmul double %.9416, %.12075\n  %.12225 = fmul double %20, 2.484040e+01\n  %.12262 = fmul double %.9416, %.12225\n  %.11972 = fsub double %.11685, %.11962\n  %.12122 = fadd double %.12112, %.11972\n  %.12272 = fadd double %.12262, %.12122\n  %.12512 = fmul double %.1401, 0x4055826809D49518\n  %.12549 = fmul double %.1023, %.12512\n  %.12559 = fsub double %.12272, %.12549\n  %.12799 = fmul double %.1815, 4.968080e+01\n  %.12836 = fmul double %.1023, %.12799\n  %.12846 = fsub double %.12559, %.12836\n  %.12886 = fmul double %.1023, 0x4053C3993351E28D\n  %.12896 = fadd double %.12886, %.12846\n  %.12936 = fmul double %.1095, 0x40249145EEA44DA2\n  %.12946 = fadd double %.12936, %.12896\n  %.12959 = fadd double %.12946, 0x406EA2E3F5B4B6E1\n  %.13286 = fmul double %.10119, 0xBFB70A3D70A3D70A\n  %.13323 = fmul double %.9416, %.13286\n  %.13650 = fmul double %.10119, 4.000000e-02\n  %.13687 = fmul double %.9780, %.13650\n  %.13697 = fsub double %.13323, %.13687\n  %.13874 = fmul double %.1164, 0x3FE3AE147AE147AE\n  %.14111 = fmul double %.13874, %.1815\n  %.14121 = fadd double %.13697, %.14111\n  %.14298 = fmul double %.11565, 0x3FB70A3D70A3D70A\n  %.14398 = fmul double %20, %.14298\n  %.14511 = fmul double %20, 4.000000e-02\n  %.14548 = fmul double %.9416, %.14511\n  %.14408 = fsub double %.14121, %.14398\n  %.14558 = fadd double %.14548, %.14408\n  %.14798 = fmul double %.1815, 8.000000e-02\n  %.14835 = fmul double %.1023, %.14798\n  %.14845 = fsub double %.14558, %.14835\n  %.14885 = fmul double %.1023, 0x3FC24B9B1B9DCB29\n  %.14895 = fadd double %.14885, %.14845\n  %.14935 = fmul double %.1095, 0x3F9309FF12551E62\n  %.14945 = fadd double %.14935, %.14895\n  %.14958 = fadd double %.14945, 0x3FE943D3A7E01384\n  %.14968 = fcmp oeq double %.14958, 0.000000e+00\n  br i1 %.14968, label %for.end.237.if, label %for.end.237.endif, !prof !0\n\nfor.end.237.if:                                   ; preds = %for.end.176\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.237.endif:                                ; preds = %for.end.176\n  %.15021 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.15022 = icmp eq i8* %.15021, null\n  br i1 %.15022, label %for.end.237.endif.endif.endif.if, label %for.end.237.endif.endif.endif.endif, !prof !0\n\nfor.end.237.endif.endif.endif.if:                 ; preds = %for.end.237.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.237.endif.endif.endif.endif:              ; preds = %for.end.237.endif\n  %.14975 = fdiv double %.12959, %.14958\n  %.14985 = fsub double %.14975, %.296\n  %.14995 = fmul double %.856, %.14985\n  %.5.i2245 = getelementptr i8, i8* %.15021, i64 24\n  %21 = bitcast i8* %.5.i2245 to { i64, i64, i8, double }**\n  %.6.i22464153 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %21, align 8\n  %.15034 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i22464153, i64 0, i32 1\n  store i64 1, i64* %.15034, align 8\n  %.6.i22444154 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %21, align 8\n  %.150404254 = bitcast { i64, i64, i8, double }* %.6.i22444154 to i64*\n  store i64 0, i64* %.150404254, align 8\n  %.6.i22424155 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %21, align 8\n  %.15046 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i22424155, i64 0, i32 2\n  store i8 0, i8* %.15046, align 1\n  %.6.i22384157 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %21, align 8\n  %.15059 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i22384157, i64 0, i32 3\n  %22 = bitcast double* %.15059 to i64*\n  store i64 0, i64* %22, align 1\n  %.6.i22343861 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %21, align 8\n  %.150864255 = bitcast { i64, i64, i8, double }* %.6.i22343861 to i64*\n  store i64 1, i64* %.150864255, align 8\n  %.6.i22303863 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %21, align 8\n  %.15099 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i22303863, i64 0, i32 3\n  store double %.14995, double* %.15099, align 8\n  %.15435 = fmul double %.9381, 0xC06832B50B0F27BB\n  %.15472 = fmul double %.9416, %.15435\n  %.15799 = fmul double %.9381, 6.452820e+01\n  %.15836 = fmul double %.9780, %.15799\n  %.15846 = fsub double %.15472, %.15836\n  %.16173 = fmul double %.10119, 0x405BF20902DE00D2\n  %.16210 = fmul double %.9416, %.16173\n  %.16220 = fsub double %.15846, %.16210\n  %.16547 = fmul double %.10119, 3.726060e+01\n  %.16584 = fmul double %.9780, %.16547\n  %.16594 = fsub double %.16220, %.16584\n  %.17018 = fadd double %.16594, %.10964\n  %.17442 = fadd double %.17018, %.11388\n  %.17619 = fmul double %.11565, 0x406832B50B0F27BB\n  %.17719 = fmul double %.11665, %.17619\n  %.17729 = fsub double %.17442, %.17719\n  %.17906 = fmul double %.11565, 0x405BF20902DE00D2\n  %.18006 = fmul double %20, %.17906\n  %.18119 = fmul double %.11665, 6.452820e+01\n  %.18156 = fmul double %.9416, %.18119\n  %.18269 = fmul double %20, 3.726060e+01\n  %.18306 = fmul double %.9416, %.18269\n  %.18016 = fsub double %.17729, %.18006\n  %.18166 = fadd double %.18156, %.18016\n  %.18316 = fadd double %.18306, %.18166\n  %.18603 = fsub double %.18316, %.12549\n  %.18890 = fsub double %.18603, %.12836\n  %.18940 = fadd double %.12886, %.18890\n  %.18990 = fadd double %.12936, %.18940\n  %.19003 = fadd double %.18990, 0x406EA2E3F5B4B6E1\n  %.19330 = fmul double %.10119, -1.800000e-01\n  %.19367 = fmul double %.9416, %.19330\n  %.19694 = fmul double %.10119, 6.000000e-02\n  %.19731 = fmul double %.9780, %.19694\n  %.19741 = fsub double %.19367, %.19731\n  %.20165 = fadd double %.19741, %.14111\n  %.20342 = fmul double %.11565, 1.800000e-01\n  %.20442 = fmul double %20, %.20342\n  %.20555 = fmul double %20, 6.000000e-02\n  %.20592 = fmul double %.9416, %.20555\n  %.20452 = fsub double %.20165, %.20442\n  %.20602 = fadd double %.20592, %.20452\n  %.20889 = fsub double %.20602, %.14835\n  %.20939 = fadd double %.14885, %.20889\n  %.20989 = fadd double %.14935, %.20939\n  %.21002 = fadd double %.20989, 0x3FE943D3A7E01384\n  %.21012 = fcmp oeq double %.21002, 0.000000e+00\n  br i1 %.21012, label %for.end.343.if, label %for.end.343.endif, !prof !0\n\nfor.end.343.if:                                   ; preds = %for.end.237.endif.endif.endif.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.343.endif:                                ; preds = %for.end.237.endif.endif.endif.endif\n  %.21065 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.21066 = icmp eq i8* %.21065, null\n  br i1 %.21066, label %for.end.343.endif.endif.endif.if, label %for.end.343.endif.endif.endif.endif, !prof !0\n\nfor.end.343.endif.endif.endif.if:                 ; preds = %for.end.343.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.343.endif.endif.endif.endif:              ; preds = %for.end.343.endif\n  %.21019 = fdiv double %.19003, %.21002\n  %.21029 = fsub double %.21019, %.336\n  %.21039 = fmul double %.896, %.21029\n  %.5.i2011 = getelementptr i8, i8* %.21065, i64 24\n  %23 = bitcast i8* %.5.i2011 to { i64, i64, i8, double }**\n  %.6.i20124147 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %23, align 8\n  %.21078 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i20124147, i64 0, i32 1\n  store i64 1, i64* %.21078, align 8\n  %.6.i20104148 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %23, align 8\n  %.210844256 = bitcast { i64, i64, i8, double }* %.6.i20104148 to i64*\n  store i64 0, i64* %.210844256, align 8\n  %.6.i20084149 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %23, align 8\n  %.21090 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i20084149, i64 0, i32 2\n  store i8 0, i8* %.21090, align 1\n  %.6.i20044151 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %23, align 8\n  %.21103 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i20044151, i64 0, i32 3\n  %24 = bitcast double* %.21103 to i64*\n  store i64 0, i64* %24, align 1\n  %.6.i20003870 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %23, align 8\n  %.211304257 = bitcast { i64, i64, i8, double }* %.6.i20003870 to i64*\n  store i64 1, i64* %.211304257, align 8\n  %.6.i19963872 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %23, align 8\n  %.21143 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i19963872, i64 0, i32 3\n  store double %.21039, double* %.21143, align 8\n  %.21479 = fmul double %.9381, 2.150940e+02\n  %.21516 = fmul double %.9416, %.21479\n  %.21843 = fmul double %.9381, 5.377350e+01\n  %.21880 = fmul double %.9780, %.21843\n  %.21890 = fsub double %.21516, %.21880\n  %.22217 = fmul double %.10119, 1.242020e+02\n  %.22254 = fmul double %.9416, %.22217\n  %.22264 = fadd double %.21890, %.22254\n  %.22591 = fmul double %.10119, 3.105050e+01\n  %.22628 = fmul double %.9780, %.22591\n  %.22638 = fsub double %.22264, %.22628\n  %.23062 = fadd double %.22638, %.10964\n  %.23486 = fadd double %.23062, %.11388\n  %.23663 = fmul double %.11565, 2.150940e+02\n  %.23763 = fmul double %.11665, %.23663\n  %.23773 = fadd double %.23486, %.23763\n  %.23950 = fmul double %.11565, 1.242020e+02\n  %.24050 = fmul double %20, %.23950\n  %.24163 = fmul double %.11665, 5.377350e+01\n  %.24200 = fmul double %.9416, %.24163\n  %.24313 = fmul double %20, 3.105050e+01\n  %.24350 = fmul double %.9416, %.24313\n  %.24060 = fadd double %.23773, %.24050\n  %.24210 = fadd double %.24200, %.24060\n  %.24360 = fadd double %.24350, %.24210\n  %.24647 = fsub double %.24360, %.12549\n  %.24934 = fsub double %.24647, %.12836\n  %.24984 = fadd double %.12886, %.24934\n  %.25034 = fadd double %.12936, %.24984\n  %.25047 = fadd double %.25034, 0x406EA2E3F5B4B6E1\n  %.25374 = fmul double %.10119, 2.000000e-01\n  %.25411 = fmul double %.9416, %.25374\n  %.25738 = fmul double %.10119, 5.000000e-02\n  %.25775 = fmul double %.9780, %.25738\n  %.25785 = fsub double %.25411, %.25775\n  %.26209 = fadd double %.25785, %.14111\n  %.26386 = fmul double %.11565, 2.000000e-01\n  %.26486 = fmul double %20, %.26386\n  %.26599 = fmul double %20, 5.000000e-02\n  %.26636 = fmul double %.9416, %.26599\n  %.26496 = fadd double %.26209, %.26486\n  %.26646 = fadd double %.26636, %.26496\n  %.26933 = fsub double %.26646, %.14835\n  %.26983 = fadd double %.14885, %.26933\n  %.27033 = fadd double %.14935, %.26983\n  %.27046 = fadd double %.27033, 0x3FE943D3A7E01384\n  %.27056 = fcmp oeq double %.27046, 0.000000e+00\n  br i1 %.27056, label %for.end.449.if, label %for.end.449.endif, !prof !0\n\nfor.end.449.if:                                   ; preds = %for.end.343.endif.endif.endif.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.449.endif:                                ; preds = %for.end.343.endif.endif.endif.endif\n  %.27109 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.27110 = icmp eq i8* %.27109, null\n  br i1 %.27110, label %for.end.449.endif.endif.endif.if, label %for.end.449.endif.endif.endif.endif, !prof !0\n\nfor.end.449.endif.endif.endif.if:                 ; preds = %for.end.449.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.449.endif.endif.endif.endif:              ; preds = %for.end.449.endif\n  %.27063 = fdiv double %.25047, %.27046\n  %.27073 = fsub double %.27063, %.376\n  %.27083 = fmul double %.936, %.27073\n  %.5.i1777 = getelementptr i8, i8* %.27109, i64 24\n  %25 = bitcast i8* %.5.i1777 to { i64, i64, i8, double }**\n  %.6.i17784141 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %25, align 8\n  %.27122 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i17784141, i64 0, i32 1\n  store i64 1, i64* %.27122, align 8\n  %.6.i17764142 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %25, align 8\n  %.271284258 = bitcast { i64, i64, i8, double }* %.6.i17764142 to i64*\n  store i64 0, i64* %.271284258, align 8\n  %.6.i17744143 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %25, align 8\n  %.27134 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i17744143, i64 0, i32 2\n  store i8 0, i8* %.27134, align 1\n  %.6.i17704145 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %25, align 8\n  %.27147 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i17704145, i64 0, i32 3\n  %26 = bitcast double* %.27147 to i64*\n  store i64 0, i64* %26, align 1\n  %.6.i17663879 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %25, align 8\n  %.271744259 = bitcast { i64, i64, i8, double }* %.6.i17663879 to i64*\n  store i64 1, i64* %.271744259, align 8\n  %.6.i17623881 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %25, align 8\n  %.27187 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i17623881, i64 0, i32 3\n  store double %.27083, double* %.27187, align 8\n  %.27523 = fmul double %.9381, 1.075470e+02\n  %.27560 = fmul double %.9416, %.27523\n  %.27934 = fsub double %.27560, %.9792\n  %.28261 = fmul double %.10119, 6.210100e+01\n  %.28298 = fmul double %.9416, %.28261\n  %.28308 = fadd double %.27934, %.28298\n  %.28682 = fsub double %.28308, %.10540\n  %.29106 = fadd double %.28682, %.10964\n  %.29530 = fadd double %.29106, %.11388\n  %.29707 = fmul double %.11565, 1.075470e+02\n  %.29807 = fmul double %.11665, %.29707\n  %.29817 = fadd double %.29530, %.29807\n  %.29994 = fmul double %.11565, 6.210100e+01\n  %.30094 = fmul double %20, %.29994\n  %.30104 = fadd double %.29817, %.30094\n  %.30254 = fadd double %.12112, %.30104\n  %.30404 = fadd double %.12262, %.30254\n  %.30691 = fsub double %.30404, %.12549\n  %.30978 = fsub double %.30691, %.12836\n  %.31028 = fadd double %.12886, %.30978\n  %.31078 = fadd double %.12936, %.31028\n  %.31091 = fadd double %.31078, 0x406EA2E3F5B4B6E1\n  %.31418 = fmul double %.10119, 1.000000e-01\n  %.31455 = fmul double %.9416, %.31418\n  %.31829 = fsub double %.31455, %.13687\n  %.32253 = fadd double %.31829, %.14111\n  %.32430 = fmul double %.11565, 1.000000e-01\n  %.32530 = fmul double %20, %.32430\n  %.32540 = fadd double %.32253, %.32530\n  %.32690 = fadd double %.14548, %.32540\n  %.32977 = fsub double %.32690, %.14835\n  %.33027 = fadd double %.14885, %.32977\n  %.33077 = fadd double %.14935, %.33027\n  %.33090 = fadd double %.33077, 0x3FE943D3A7E01384\n  %.33100 = fcmp oeq double %.33090, 0.000000e+00\n  br i1 %.33100, label %for.end.555.if, label %for.end.555.endif, !prof !0\n\nfor.end.555.if:                                   ; preds = %for.end.449.endif.endif.endif.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904318645176, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.555.endif:                                ; preds = %for.end.449.endif.endif.endif.endif\n  %.33153 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.33154 = icmp eq i8* %.33153, null\n  br i1 %.33154, label %for.end.555.endif.endif.endif.if, label %for.end.599.endif, !prof !0\n\nfor.end.555.endif.endif.endif.if:                 ; preds = %for.end.555.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.599.endif:                                ; preds = %for.end.555.endif\n  %.33107 = fdiv double %.31091, %.33090\n  %.33117 = fsub double %.33107, %.416\n  %.33127 = fmul double %.976, %.33117\n  %.5.i1543 = getelementptr i8, i8* %.33153, i64 24\n  %27 = bitcast i8* %.5.i1543 to { i64, i64, i8, double }**\n  %.6.i15444135 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %27, align 8\n  %.33166 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i15444135, i64 0, i32 1\n  store i64 1, i64* %.33166, align 8\n  %.6.i15424136 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %27, align 8\n  %.331724260 = bitcast { i64, i64, i8, double }* %.6.i15424136 to i64*\n  store i64 0, i64* %.331724260, align 8\n  %.6.i15404137 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %27, align 8\n  %.33178 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i15404137, i64 0, i32 2\n  store i8 0, i8* %.33178, align 1\n  %.6.i15364139 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %27, align 8\n  %.33191 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i15364139, i64 0, i32 3\n  %28 = bitcast double* %.33191 to i64*\n  store i64 0, i64* %28, align 1\n  %.6.i15323888 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %27, align 8\n  %.332184261 = bitcast { i64, i64, i8, double }* %.6.i15323888 to i64*\n  store i64 1, i64* %.332184261, align 8\n  %.6.i15283890 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %27, align 8\n  %.33231 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i15283890, i64 0, i32 3\n  store double %.33127, double* %.33231, align 8\n  %.33907 = fmul double %.376.i15, 0x3FB76DAF331851D4\n  %.33951 = fdiv double %.33907, %.1275\n  %.33991 = fmul double %.1202, 0x3FCB68D33F88E740\n  %.34001 = fsub double %.33951, %.33991\n  %.34048 = fdiv double 0x3FB76DAF331851D4, %.1275\n  %.34058 = fsub double %.34001, %.34048\n  %.34318 = fmul double %.1815, 1.451200e+01\n  %.34355 = fmul double %.1023, %.34318\n  %.34605 = fmul double %.34058, 4.308880e+01\n  %.34642 = fmul double %.1023, %.34605\n  %.34692 = fmul double %.1202, 0x3FE376714D6E5D36\n  %.34792 = fmul double %.1275, 0x3FEAEC6DD102232D\n  %.34842 = fmul double %.1095, 0x4046A3718E2D7617\n  %.35844 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.35845 = icmp eq i8* %.35844, null\n  br i1 %.35845, label %for.end.599.endif.endif.endif.if, label %for.end.643.endif, !prof !0\n\nfor.end.599.endif.endif.endif.if:                 ; preds = %for.end.599.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.643.endif:                                ; preds = %for.end.599.endif\n  %.33417 = fmul double %.1164, -4.716400e+01\n  %.33654 = fmul double %.33417, %.1815\n  %.33831 = fmul double %.1164, 0x4061813C36113405\n  %.34068 = fmul double %.33831, %.34058\n  %.34078 = fsub double %.33654, %.34068\n  %.34365 = fsub double %.34078, %.34355\n  %.34652 = fsub double %.34365, %.34642\n  %.34702 = fadd double %.34692, %.34652\n  %.34742 = fmul double %.1023, 0x406264CC4384F000\n  %.34752 = fsub double %.34702, %.34742\n  %.34802 = fsub double %.34752, %.34792\n  %.34852 = fadd double %.34842, %.34802\n  %.34865 = fadd double %.34852, 0x404A39663494959A\n  %.35796 = fdiv double %.34865, %.3536\n  %.35806 = fsub double %.35796, %.456\n  %.35816 = fmul double %.736, %.35806\n  %.5.i1417 = getelementptr i8, i8* %.35844, i64 24\n  %29 = bitcast i8* %.5.i1417 to { i64, i64, i8, double }**\n  %.6.i14184129 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %29, align 8\n  %.35857 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i14184129, i64 0, i32 1\n  store i64 1, i64* %.35857, align 8\n  %.6.i14164130 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %29, align 8\n  %.358634262 = bitcast { i64, i64, i8, double }* %.6.i14164130 to i64*\n  store i64 0, i64* %.358634262, align 8\n  %.6.i14144131 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %29, align 8\n  %.35869 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i14144131, i64 0, i32 2\n  store i8 0, i8* %.35869, align 1\n  %.6.i14104133 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %29, align 8\n  %.35882 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i14104133, i64 0, i32 3\n  %30 = bitcast double* %.35882 to i64*\n  store i64 0, i64* %30, align 1\n  %.6.i14063894 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %29, align 8\n  %.359094263 = bitcast { i64, i64, i8, double }* %.6.i14063894 to i64*\n  store i64 1, i64* %.359094263, align 8\n  %.6.i14023896 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %29, align 8\n  %.35922 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i14023896, i64 0, i32 3\n  store double %.35816, double* %.35922, align 8\n  %.38535 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.38536 = icmp eq i8* %.38535, null\n  br i1 %.38536, label %for.end.643.endif.endif.endif.if, label %for.end.687.endif, !prof !0\n\nfor.end.643.endif.endif.endif.if:                 ; preds = %for.end.643.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.687.endif:                                ; preds = %for.end.643.endif\n  %.37433 = fmul double %.1023, 0x406977DFBFF324E7\n  %.36108 = fmul double %.1164, 6.530400e+01\n  %.36345 = fmul double %.36108, %.1815\n  %.36522 = fmul double %.1164, 0x40683CC985F06F69\n  %.36759 = fmul double %.36522, %.34058\n  %.36769 = fadd double %.36345, %.36759\n  %.37056 = fsub double %.36769, %.34355\n  %.37343 = fsub double %.37056, %.34642\n  %.37393 = fadd double %.34692, %.37343\n  %.37443 = fadd double %.37433, %.37393\n  %.37493 = fsub double %.37443, %.34792\n  %.37543 = fadd double %.34842, %.37493\n  %.37556 = fadd double %.37543, 0x404A39663494959A\n  %.38487 = fdiv double %.37556, %.6225\n  %.38497 = fsub double %.38487, %.496\n  %.38507 = fmul double %.776, %.38497\n  %.5.i1291 = getelementptr i8, i8* %.38535, i64 24\n  %31 = bitcast i8* %.5.i1291 to { i64, i64, i8, double }**\n  %.6.i12924123 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %31, align 8\n  %.38548 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i12924123, i64 0, i32 1\n  store i64 1, i64* %.38548, align 8\n  %.6.i12904124 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %31, align 8\n  %.385544264 = bitcast { i64, i64, i8, double }* %.6.i12904124 to i64*\n  store i64 0, i64* %.385544264, align 8\n  %.6.i12884125 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %31, align 8\n  %.38560 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i12884125, i64 0, i32 2\n  store i8 0, i8* %.38560, align 1\n  %.6.i12844127 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %31, align 8\n  %.38573 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i12844127, i64 0, i32 3\n  %32 = bitcast double* %.38573 to i64*\n  store i64 0, i64* %32, align 1\n  %.6.i12803900 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %31, align 8\n  %.386004265 = bitcast { i64, i64, i8, double }* %.6.i12803900 to i64*\n  store i64 1, i64* %.386004265, align 8\n  %.6.i12763902 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %31, align 8\n  %.38613 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i12763902, i64 0, i32 3\n  store double %.38507, double* %.38613, align 8\n  %.41226 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.41227 = icmp eq i8* %.41226, null\n  br i1 %.41227, label %for.end.687.endif.endif.endif.if, label %for.end.793.endif, !prof !0\n\nfor.end.687.endif.endif.endif.if:                 ; preds = %for.end.687.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.793.endif:                                ; preds = %for.end.687.endif\n  %.40124 = fmul double %.1023, 0x407E6BA0970D16B5\n  %.38799 = fmul double %.1164, 1.560040e+02\n  %.39036 = fmul double %.38799, %.1815\n  %.39213 = fmul double %.1164, 0x407CF3460AA64C30\n  %.39450 = fmul double %.39213, %.34058\n  %.39460 = fadd double %.39036, %.39450\n  %.39747 = fsub double %.39460, %.34355\n  %.40034 = fsub double %.39747, %.34642\n  %.40084 = fadd double %.34692, %.40034\n  %.40134 = fadd double %.40124, %.40084\n  %.40184 = fsub double %.40134, %.34792\n  %.40234 = fadd double %.34842, %.40184\n  %.40247 = fadd double %.40234, 0x404A39663494959A\n  %.41178 = fdiv double %.40247, %.8914\n  %.41188 = fsub double %.41178, %.536\n  %.41198 = fmul double %.816, %.41188\n  %.5.i1165 = getelementptr i8, i8* %.41226, i64 24\n  %33 = bitcast i8* %.5.i1165 to { i64, i64, i8, double }**\n  %.6.i11664117 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %33, align 8\n  %.41239 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i11664117, i64 0, i32 1\n  store i64 1, i64* %.41239, align 8\n  %.6.i11644118 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %33, align 8\n  %.412454266 = bitcast { i64, i64, i8, double }* %.6.i11644118 to i64*\n  store i64 0, i64* %.412454266, align 8\n  %.6.i11624119 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %33, align 8\n  %.41251 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i11624119, i64 0, i32 2\n  store i8 0, i8* %.41251, align 1\n  %.6.i11584121 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %33, align 8\n  %.41264 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i11584121, i64 0, i32 3\n  %34 = bitcast double* %.41264 to i64*\n  store i64 0, i64* %34, align 1\n  %.6.i11543906 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %33, align 8\n  %.412914267 = bitcast { i64, i64, i8, double }* %.6.i11543906 to i64*\n  store i64 1, i64* %.412914267, align 8\n  %.6.i11503908 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %33, align 8\n  %.41304 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i11503908, i64 0, i32 3\n  store double %.41198, double* %.41304, align 8\n  %.42004 = fmul double %.10119, 1.451200e+01\n  %.42041 = fmul double %.9780, %.42004\n  %.42318 = fmul double %.1023, %.34058\n  %.42358 = fmul double %.1095, 0x3FEF1EC746691B26\n  %.42368 = fsub double %.42318, %.42358\n  %.42752 = fmul double %.42368, 4.308880e+01\n  %.42789 = fmul double %.9780, %.42752\n  %.42976 = fmul double %.1164, 2.231220e+02\n  %.43213 = fmul double %.42976, %.1815\n  %.43400 = fmul double %.1164, 0x4084B3EC226809D5\n  %.43637 = fmul double %.43400, %.34058\n  %.44151 = fmul double %.1202, 0x3FB76DAF331851D4\n  %.44191 = fmul double %.1275, 0x3FCB68D33F88E740\n  %.44201 = fsub double %.44151, %.44191\n  %.44324 = fmul double %20, 1.451200e+01\n  %.44361 = fmul double %.9416, %.44324\n  %.44474 = fmul double %.44201, 4.308880e+01\n  %.44511 = fmul double %.9416, %.44474\n  %.44761 = fmul double %.1815, 2.902400e+01\n  %.44798 = fmul double %.1023, %.44761\n  %.45048 = fmul double %.34058, 0x40558B5DCC63F141\n  %.45085 = fmul double %.1023, %.45048\n  %.45135 = fmul double %.1023, 0x4085C10F1E9FAF80\n  %.45185 = fmul double %.1095, 0x4056A3718E2D7617\n  %.47272 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.47273 = icmp eq i8* %.47272, null\n  br i1 %.47273, label %for.end.793.endif.endif.endif.if, label %for.end.899.endif, !prof !0\n\nfor.end.793.endif.endif.endif.if:                 ; preds = %for.end.793.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.899.endif:                                ; preds = %for.end.793.endif\n  %.41640 = fmul double %.10119, -3.265200e+01\n  %.41677 = fmul double %.9416, %.41640\n  %.42051 = fsub double %.41677, %.42041\n  %.42378 = fmul double %.42368, 0x40583CC985F06F69\n  %.42415 = fmul double %.9416, %.42378\n  %.42425 = fsub double %.42051, %.42415\n  %.42799 = fsub double %.42425, %.42789\n  %.43223 = fadd double %.42799, %.43213\n  %.43647 = fadd double %.43223, %.43637\n  %.43824 = fmul double %.11565, 3.265200e+01\n  %.43924 = fmul double %20, %.43824\n  %.43934 = fsub double %.43647, %.43924\n  %.44111 = fmul double %.11565, 0x40583CC985F06F69\n  %.44211 = fmul double %.44201, %.44111\n  %.44221 = fsub double %.43934, %.44211\n  %.44371 = fadd double %.44361, %.44221\n  %.44521 = fadd double %.44511, %.44371\n  %.44808 = fsub double %.44521, %.44798\n  %.45095 = fsub double %.44808, %.45085\n  %.45145 = fadd double %.45135, %.45095\n  %.45195 = fadd double %.45185, %.45145\n  %.45208 = fadd double %.45195, 0x404A39663494959A\n  %.47224 = fdiv double %.45208, %.14958\n  %.47234 = fsub double %.47224, %.576\n  %.47244 = fmul double %.856, %.47234\n  %.5.i931 = getelementptr i8, i8* %.47272, i64 24\n  %35 = bitcast i8* %.5.i931 to { i64, i64, i8, double }**\n  %.6.i9324111 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %35, align 8\n  %.47285 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i9324111, i64 0, i32 1\n  store i64 1, i64* %.47285, align 8\n  %.6.i9304112 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %35, align 8\n  %.472914268 = bitcast { i64, i64, i8, double }* %.6.i9304112 to i64*\n  store i64 0, i64* %.472914268, align 8\n  %.6.i9284113 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %35, align 8\n  %.47297 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i9284113, i64 0, i32 2\n  store i8 0, i8* %.47297, align 1\n  %.6.i9244115 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %35, align 8\n  %.47310 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i9244115, i64 0, i32 3\n  %36 = bitcast double* %.47310 to i64*\n  store i64 0, i64* %36, align 1\n  %.6.i9203915 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %35, align 8\n  %.473374269 = bitcast { i64, i64, i8, double }* %.6.i9203915 to i64*\n  store i64 1, i64* %.473374269, align 8\n  %.6.i9163917 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %35, align 8\n  %.47350 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i9163917, i64 0, i32 3\n  store double %.47244, double* %.47350, align 8\n  %.53318 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.53319 = icmp eq i8* %.53318, null\n  br i1 %.53319, label %for.end.899.endif.endif.endif.if, label %for.end.1005.endif, !prof !0\n\nfor.end.899.endif.endif.endif.if:                 ; preds = %for.end.899.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.1005.endif:                               ; preds = %for.end.899.endif\n  %.50520 = fmul double %.44201, 6.463320e+01\n  %.50557 = fmul double %.9416, %.50520\n  %.50370 = fmul double %20, 2.176800e+01\n  %.50407 = fmul double %.9416, %.50370\n  %.47686 = fmul double %.10119, -6.530400e+01\n  %.47723 = fmul double %.9416, %.47686\n  %.48050 = fmul double %.10119, 2.176800e+01\n  %.48087 = fmul double %.9780, %.48050\n  %.48097 = fsub double %.47723, %.48087\n  %.48424 = fmul double %.42368, 0x40683CC985F06F69\n  %.48461 = fmul double %.9416, %.48424\n  %.48471 = fsub double %.48097, %.48461\n  %.48798 = fmul double %.42368, 6.463320e+01\n  %.48835 = fmul double %.9780, %.48798\n  %.48845 = fsub double %.48471, %.48835\n  %.49269 = fadd double %.48845, %.43213\n  %.49693 = fadd double %.49269, %.43637\n  %.49870 = fmul double %.11565, 6.530400e+01\n  %.49970 = fmul double %20, %.49870\n  %.49980 = fsub double %.49693, %.49970\n  %.50157 = fmul double %.11565, 0x40683CC985F06F69\n  %.50257 = fmul double %.44201, %.50157\n  %.50267 = fsub double %.49980, %.50257\n  %.50417 = fadd double %.50407, %.50267\n  %.50567 = fadd double %.50557, %.50417\n  %.50854 = fsub double %.50567, %.44798\n  %.51141 = fsub double %.50854, %.45085\n  %.51191 = fadd double %.45135, %.51141\n  %.51241 = fadd double %.45185, %.51191\n  %.51254 = fadd double %.51241, 0x404A39663494959A\n  %.53270 = fdiv double %.51254, %.21002\n  %.53280 = fsub double %.53270, %.616\n  %.53290 = fmul double %.896, %.53280\n  %.5.i697 = getelementptr i8, i8* %.53318, i64 24\n  %37 = bitcast i8* %.5.i697 to { i64, i64, i8, double }**\n  %.6.i6984105 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %37, align 8\n  %.53331 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i6984105, i64 0, i32 1\n  store i64 1, i64* %.53331, align 8\n  %.6.i6964106 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %37, align 8\n  %.533374270 = bitcast { i64, i64, i8, double }* %.6.i6964106 to i64*\n  store i64 0, i64* %.533374270, align 8\n  %.6.i6944107 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %37, align 8\n  %.53343 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i6944107, i64 0, i32 2\n  store i8 0, i8* %.53343, align 1\n  %.6.i6904109 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %37, align 8\n  %.53356 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i6904109, i64 0, i32 3\n  %38 = bitcast double* %.53356 to i64*\n  store i64 0, i64* %38, align 1\n  %.6.i6863924 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %37, align 8\n  %.533834271 = bitcast { i64, i64, i8, double }* %.6.i6863924 to i64*\n  store i64 1, i64* %.533834271, align 8\n  %.6.i6823926 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %37, align 8\n  %.53396 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i6823926, i64 0, i32 3\n  store double %.53290, double* %.53396, align 8\n  %.59364 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.59365 = icmp eq i8* %.59364, null\n  br i1 %.59365, label %for.end.1005.endif.endif.endif.if, label %for.end.1111.endif, !prof !0\n\nfor.end.1005.endif.endif.endif.if:                ; preds = %for.end.1005.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.1111.endif:                               ; preds = %for.end.1005.endif\n  %.56566 = fmul double %.44201, 5.386100e+01\n  %.56603 = fmul double %.9416, %.56566\n  %.56416 = fmul double %20, 1.814000e+01\n  %.56453 = fmul double %.9416, %.56416\n  %.53732 = fmul double %.10119, 7.256000e+01\n  %.53769 = fmul double %.9416, %.53732\n  %.54096 = fmul double %.10119, 1.814000e+01\n  %.54133 = fmul double %.9780, %.54096\n  %.54143 = fsub double %.53769, %.54133\n  %.54470 = fmul double %.42368, 2.154440e+02\n  %.54507 = fmul double %.9416, %.54470\n  %.54517 = fadd double %.54143, %.54507\n  %.54844 = fmul double %.42368, 5.386100e+01\n  %.54881 = fmul double %.9780, %.54844\n  %.54891 = fsub double %.54517, %.54881\n  %.55315 = fadd double %.54891, %.43213\n  %.55739 = fadd double %.55315, %.43637\n  %.55916 = fmul double %.11565, 7.256000e+01\n  %.56016 = fmul double %20, %.55916\n  %.56026 = fadd double %.55739, %.56016\n  %.56203 = fmul double %.11565, 2.154440e+02\n  %.56303 = fmul double %.44201, %.56203\n  %.56313 = fadd double %.56026, %.56303\n  %.56463 = fadd double %.56453, %.56313\n  %.56613 = fadd double %.56603, %.56463\n  %.56900 = fsub double %.56613, %.44798\n  %.57187 = fsub double %.56900, %.45085\n  %.57237 = fadd double %.45135, %.57187\n  %.57287 = fadd double %.45185, %.57237\n  %.57300 = fadd double %.57287, 0x404A39663494959A\n  %.59316 = fdiv double %.57300, %.27046\n  %.59326 = fsub double %.59316, %.656\n  %.59336 = fmul double %.936, %.59326\n  %.5.i463 = getelementptr i8, i8* %.59364, i64 24\n  %39 = bitcast i8* %.5.i463 to { i64, i64, i8, double }**\n  %.6.i4644099 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %39, align 8\n  %.59377 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i4644099, i64 0, i32 1\n  store i64 1, i64* %.59377, align 8\n  %.6.i4624100 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %39, align 8\n  %.593834272 = bitcast { i64, i64, i8, double }* %.6.i4624100 to i64*\n  store i64 0, i64* %.593834272, align 8\n  %.6.i4604101 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %39, align 8\n  %.59389 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i4604101, i64 0, i32 2\n  store i8 0, i8* %.59389, align 1\n  %.6.i4564103 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %39, align 8\n  %.59402 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i4564103, i64 0, i32 3\n  %40 = bitcast double* %.59402 to i64*\n  store i64 0, i64* %40, align 1\n  %.6.i4523933 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %39, align 8\n  %.594294273 = bitcast { i64, i64, i8, double }* %.6.i4523933 to i64*\n  store i64 1, i64* %.594294273, align 8\n  %.6.i4483935 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %39, align 8\n  %.59442 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i4483935, i64 0, i32 3\n  store double %.59336, double* %.59442, align 8\n  %.65416 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 32, i8* bitcast (void (i8*)* @.dtor.list.float64 to i8*))\n  %.65417 = icmp eq i8* %.65416, null\n  br i1 %.65417, label %for.end.1111.endif.endif.endif.if, label %for.end.1111.endif.endif.endif.endif, !prof !0\n\nfor.end.1111.endif.endif.endif.if:                ; preds = %for.end.1111.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.1111.endif.endif.endif.endif:             ; preds = %for.end.1111.endif\n  %.59778 = fmul double %.10119, 3.628000e+01\n  %.59815 = fmul double %.9416, %.59778\n  %.60189 = fsub double %.59815, %.42041\n  %.60516 = fmul double %.42368, 1.077220e+02\n  %.60553 = fmul double %.9416, %.60516\n  %.60563 = fadd double %.60189, %.60553\n  %.60937 = fsub double %.60563, %.42789\n  %.61361 = fadd double %.60937, %.43213\n  %.61785 = fadd double %.61361, %.43637\n  %.61962 = fmul double %.11565, 3.628000e+01\n  %.62062 = fmul double %20, %.61962\n  %.62072 = fadd double %.61785, %.62062\n  %.62249 = fmul double %.11565, 1.077220e+02\n  %.62349 = fmul double %.44201, %.62249\n  %.62359 = fadd double %.62072, %.62349\n  %.62509 = fadd double %.44361, %.62359\n  %.62659 = fadd double %.44511, %.62509\n  %.62946 = fsub double %.62659, %.44798\n  %.63233 = fsub double %.62946, %.45085\n  %.63283 = fadd double %.45135, %.63233\n  %.63333 = fadd double %.45185, %.63283\n  %.63346 = fadd double %.63333, 0x404A39663494959A\n  %.65368 = fdiv double %.63346, %.33090\n  %.65378 = fsub double %.65368, %.696\n  %.65388 = fmul double %.976, %.65378\n  %.5.i229 = getelementptr i8, i8* %.65416, i64 24\n  %41 = bitcast i8* %.5.i229 to { i64, i64, i8, double }**\n  %.6.i2304093 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %41, align 8\n  %.65429 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i2304093, i64 0, i32 1\n  store i64 1, i64* %.65429, align 8\n  %.6.i2284094 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %41, align 8\n  %.654354274 = bitcast { i64, i64, i8, double }* %.6.i2284094 to i64*\n  store i64 0, i64* %.654354274, align 8\n  %.6.i2264095 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %41, align 8\n  %.65441 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i2264095, i64 0, i32 2\n  store i8 0, i8* %.65441, align 1\n  %.6.i2224097 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %41, align 8\n  %.65454 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i2224097, i64 0, i32 3\n  %42 = bitcast double* %.65454 to i64*\n  store i64 0, i64* %42, align 1\n  %.6.i2183942 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %41, align 8\n  %.654814275 = bitcast { i64, i64, i8, double }* %.6.i2183942 to i64*\n  store i64 1, i64* %.654814275, align 8\n  %.6.i2143944 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %41, align 8\n  %.65494 = getelementptr inbounds { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i2143944, i64 0, i32 3\n  store double %.65388, double* %.65494, align 8\n  %.65537 = tail call i8* @NRT_MemInfo_new_varsize_dtor(i64 248, i8* bitcast (void (i8*)* @".dtor.list.list(float64)<iv=None>" to i8*))\n  %.65538 = icmp eq i8* %.65537, null\n  br i1 %.65538, label %for.end.1111.endif.endif.endif.endif.endif.endif.if, label %for.end.1111.endif.endif.endif.endif.endif.endif.endif, !prof !0\n\nfor.end.1111.endif.endif.endif.endif.endif.endif.if: ; preds = %for.end.1111.endif.endif.endif.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904360040792, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.1111.endif.endif.endif.endif.endif.endif.endif: ; preds = %for.end.1111.endif.endif.endif.endif\n  %.5.i211 = getelementptr i8, i8* %.65537, i64 24\n  %43 = bitcast i8* %.5.i211 to { i64, i64, i8, { i8*, i8* } }**\n  %.6.i2124087 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65550 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i2124087, i64 0, i32 1\n  store i64 14, i64* %.65550, align 8\n  %.6.i2104088 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.655564276 = bitcast { i64, i64, i8, { i8*, i8* } }* %.6.i2104088 to i64*\n  store i64 0, i64* %.655564276, align 8\n  %.6.i2084089 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65562 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i2084089, i64 0, i32 2\n  store i8 0, i8* %.65562, align 1\n  %.6.i2044091 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65575 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i2044091, i64 0, i32 3\n  %.65586 = bitcast { i8*, i8* }* %.65575 to i8*\n  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 1 dereferenceable(224) %.65586, i8 0, i64 224, i1 false)\n  %.6.i2003945 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.656024277 = bitcast { i64, i64, i8, { i8*, i8* } }* %.6.i2003945 to i64*\n  store i64 14, i64* %.656024277, align 8\n  %.6.i1983946 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65610.elt = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1983946, i64 0, i32 3, i32 0\n  %.65610.unpack = load i8*, i8** %.65610.elt, align 8\n  store i8* %.3599, i8** %.65610.elt, align 8\n  %.65618.repack3951 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1983946, i64 0, i32 3, i32 1\n  store i8* null, i8** %.65618.repack3951, align 8\n  %.6.i1943953 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65628 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1943953, i64 0, i32 3\n  %.65630.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65628, i64 1, i32 0\n  %.65630.unpack = load i8*, i8** %.65630.elt, align 8\n  store i8* %.6288, i8** %.65630.elt, align 8\n  %.65639.repack3958 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65628, i64 1, i32 1\n  store i8* null, i8** %.65639.repack3958, align 8\n  %.6.i1903960 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65648 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1903960, i64 0, i32 3\n  %.65650.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65648, i64 2, i32 0\n  %.65650.unpack = load i8*, i8** %.65650.elt, align 8\n  store i8* %.8977, i8** %.65650.elt, align 8\n  %.65659.repack3965 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65648, i64 2, i32 1\n  store i8* null, i8** %.65659.repack3965, align 8\n  %.6.i1863967 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65668 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1863967, i64 0, i32 3\n  %.65670.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65668, i64 3, i32 0\n  %.65670.unpack = load i8*, i8** %.65670.elt, align 8\n  store i8* %.15021, i8** %.65670.elt, align 8\n  %.65679.repack3972 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65668, i64 3, i32 1\n  store i8* null, i8** %.65679.repack3972, align 8\n  %.6.i1823974 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65688 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1823974, i64 0, i32 3\n  %.65690.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65688, i64 4, i32 0\n  %.65690.unpack = load i8*, i8** %.65690.elt, align 8\n  store i8* %.21065, i8** %.65690.elt, align 8\n  %.65699.repack3979 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65688, i64 4, i32 1\n  store i8* null, i8** %.65699.repack3979, align 8\n  %.6.i1783981 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65708 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1783981, i64 0, i32 3\n  %.65710.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65708, i64 5, i32 0\n  %.65710.unpack = load i8*, i8** %.65710.elt, align 8\n  store i8* %.27109, i8** %.65710.elt, align 8\n  %.65719.repack3986 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65708, i64 5, i32 1\n  store i8* null, i8** %.65719.repack3986, align 8\n  %.6.i1743988 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65728 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1743988, i64 0, i32 3\n  %.65730.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65728, i64 6, i32 0\n  %.65730.unpack = load i8*, i8** %.65730.elt, align 8\n  store i8* %.33153, i8** %.65730.elt, align 8\n  %.65739.repack3993 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65728, i64 6, i32 1\n  store i8* null, i8** %.65739.repack3993, align 8\n  %.6.i1703995 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65748 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1703995, i64 0, i32 3\n  %.65750.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65748, i64 7, i32 0\n  %.65750.unpack = load i8*, i8** %.65750.elt, align 8\n  store i8* %.35844, i8** %.65750.elt, align 8\n  %.65759.repack4000 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65748, i64 7, i32 1\n  store i8* null, i8** %.65759.repack4000, align 8\n  %.6.i1664002 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65768 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1664002, i64 0, i32 3\n  %.65770.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65768, i64 8, i32 0\n  %.65770.unpack = load i8*, i8** %.65770.elt, align 8\n  store i8* %.38535, i8** %.65770.elt, align 8\n  %.65779.repack4007 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65768, i64 8, i32 1\n  store i8* null, i8** %.65779.repack4007, align 8\n  %.6.i1624009 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65788 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1624009, i64 0, i32 3\n  %.65790.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65788, i64 9, i32 0\n  %.65790.unpack = load i8*, i8** %.65790.elt, align 8\n  store i8* %.41226, i8** %.65790.elt, align 8\n  %.65799.repack4014 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65788, i64 9, i32 1\n  store i8* null, i8** %.65799.repack4014, align 8\n  %.6.i1584016 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65808 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1584016, i64 0, i32 3\n  %.65810.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65808, i64 10, i32 0\n  %.65810.unpack = load i8*, i8** %.65810.elt, align 8\n  store i8* %.47272, i8** %.65810.elt, align 8\n  %.65819.repack4021 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65808, i64 10, i32 1\n  store i8* null, i8** %.65819.repack4021, align 8\n  %.6.i1544023 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65828 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1544023, i64 0, i32 3\n  %.65830.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65828, i64 11, i32 0\n  %.65830.unpack = load i8*, i8** %.65830.elt, align 8\n  store i8* %.53318, i8** %.65830.elt, align 8\n  %.65839.repack4028 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65828, i64 11, i32 1\n  store i8* null, i8** %.65839.repack4028, align 8\n  %.6.i1504030 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65848 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1504030, i64 0, i32 3\n  %.65850.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65848, i64 12, i32 0\n  %.65850.unpack = load i8*, i8** %.65850.elt, align 8\n  store i8* %.59364, i8** %.65850.elt, align 8\n  %.65859.repack4035 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65848, i64 12, i32 1\n  store i8* null, i8** %.65859.repack4035, align 8\n  %.6.i1464037 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.65868 = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i1464037, i64 0, i32 3\n  %.65870.elt = getelementptr { i8*, i8* }, { i8*, i8* }* %.65868, i64 13, i32 0\n  %.65870.unpack = load i8*, i8** %.65870.elt, align 8\n  store i8* %.65416, i8** %.65870.elt, align 8\n  %.65879.repack4042 = getelementptr { i8*, i8* }, { i8*, i8* }* %.65868, i64 13, i32 1\n  store i8* null, i8** %.65879.repack4042, align 8\n  %.6.i1424044 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %43, align 8\n  %.659404278 = bitcast { i64, i64, i8, { i8*, i8* } }* %.6.i1424044 to i64*\n  %.65941 = load i64, i64* %.659404278, align 8\n  %.65962 = icmp slt i64 %.65941, 1\n  tail call void @NRT_decref(i8* %.65610.unpack)\n  tail call void @NRT_decref(i8* %.65630.unpack)\n  tail call void @NRT_decref(i8* %.65650.unpack)\n  tail call void @NRT_decref(i8* %.65670.unpack)\n  tail call void @NRT_decref(i8* %.65690.unpack)\n  tail call void @NRT_decref(i8* %.65710.unpack)\n  tail call void @NRT_decref(i8* %.65730.unpack)\n  tail call void @NRT_decref(i8* %.65750.unpack)\n  tail call void @NRT_decref(i8* %.65770.unpack)\n  tail call void @NRT_decref(i8* %.65790.unpack)\n  tail call void @NRT_decref(i8* %.65810.unpack)\n  tail call void @NRT_decref(i8* %.65830.unpack)\n  tail call void @NRT_decref(i8* %.65850.unpack)\n  tail call void @NRT_decref(i8* %.65870.unpack)\n  br i1 %.65962, label %for.end.1111.endif.endif....if, label %for.end.1111.endif.endif....endif, !prof !0\n\nfor.end.1111.endif.endif....if:                   ; preds = %for.end.1111.endif.endif.endif.endif.endif.endif.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904697620984, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.1111.endif.endif....endif:                ; preds = %for.end.1111.endif.endif.endif.endif.endif.endif.endif\n  %44 = bitcast i8* %.5.i211 to { i64, i64, i8, { i8*, i8* } }**\n  %.6.i384047 = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %44, align 8\n  %.65976.elt = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i384047, i64 0, i32 3, i32 0\n  %.65976.unpack = load i8*, i8** %.65976.elt, align 8\n  %.5.i35 = getelementptr i8, i8* %.65976.unpack, i64 24\n  %45 = bitcast i8* %.5.i35 to { i64, i64, i8, double }**\n  %.6.i364051 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %45, align 8\n  %.659894279 = bitcast { i64, i64, i8, double }* %.6.i364051 to i64*\n  %.65990 = load i64, i64* %.659894279, align 8\n  %.659994280 = bitcast { i64, i64, i8, { i8*, i8* } }* %.6.i384047 to i64*\n  %.66000 = load i64, i64* %.659994280, align 8\n  %.66001 = icmp eq i64 %.66000, %.65941\n  br i1 %.66001, label %for.body.1112.preheader, label %for.end.1111.endif.endif....endif.if, !prof !2\n\nfor.body.1112.preheader:                          ; preds = %for.end.1111.endif.endif....endif\n  %scevgep4242 = getelementptr { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i384047, i64 0, i32 3, i32 0\n  %scevgep42424243 = bitcast i8** %scevgep4242 to { i64, i64, i8, { i8*, i8* } }*\n  br label %for.body.1112.endif\n\nfor.end.1111.endif.endif....endif.if:             ; preds = %for.end.1111.endif.endif....endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904700834024, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.cond.1112:                                    ; preds = %for.body.1112.endif\n  %scevgep4245 = getelementptr { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %lsr.iv4244, i64 0, i32 2\n  %46 = bitcast i8* %scevgep4245 to { i64, i64, i8, { i8*, i8* } }*\n  %lsr.iv.next = add i64 %lsr.iv4247, -1\n  %exitcond4227 = icmp eq i64 %lsr.iv.next, 0\n  br i1 %exitcond4227, label %for.end.1112, label %for.body.1112.endif\n\nfor.end.1112:                                     ; preds = %for.cond.1112\n  %.66076 = tail call { i64, i1 } @llvm.smul.with.overflow.i64(i64 %.65941, i64 %.65990)\n  %.66077 = extractvalue { i64, i1 } %.66076, 0\n  %.66078 = extractvalue { i64, i1 } %.66076, 1\n  %.66080 = shl i64 %.65990, 3\n  %.66081 = tail call { i64, i1 } @llvm.smul.with.overflow.i64(i64 %.66077, i64 8)\n  %.66083 = extractvalue { i64, i1 } %.66081, 1\n  %.66084 = or i1 %.66078, %.66083\n  br i1 %.66084, label %for.end.1112.if, label %for.body.1113.preheader, !prof !0\n\nfor.body.1112.endif:                              ; preds = %for.body.1112.preheader, %for.cond.1112\n  %lsr.iv4247 = phi i64 [ %.65941, %for.body.1112.preheader ], [ %lsr.iv.next, %for.cond.1112 ]\n  %lsr.iv4244 = phi { i64, i64, i8, { i8*, i8* } }* [ %scevgep42424243, %for.body.1112.preheader ], [ %46, %for.cond.1112 ]\n  %lsr.iv42444246 = bitcast { i64, i64, i8, { i8*, i8* } }* %lsr.iv4244 to i8**\n  %.66045.unpack = load i8*, i8** %lsr.iv42444246, align 8\n  %.5.i25 = getelementptr i8, i8* %.66045.unpack, i64 24\n  %47 = bitcast i8* %.5.i25 to { i64, i64, i8, double }**\n  %.6.i264086 = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %47, align 8\n  %.660584281 = bitcast { i64, i64, i8, double }* %.6.i264086 to i64*\n  %.66059 = load i64, i64* %.660584281, align 8\n  %.66060 = icmp eq i64 %.66059, %.65990\n  br i1 %.66060, label %for.cond.1112, label %for.body.1112.endif.if, !prof !2\n\nfor.body.1112.endif.if:                           ; preds = %for.body.1112.endif\n  store { i8*, i32, i8* }* @.const.picklebuf.1904700834024, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.end.1112.if:                                  ; preds = %for.end.1112\n  store { i8*, i32, i8* }* @.const.picklebuf.1904699354552, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.body.1113.preheader:                          ; preds = %for.end.1112\n  %.66082 = extractvalue { i64, i1 } %.66081, 0\n  %.66091 = tail call i8* @NRT_MemInfo_alloc_safe_aligned(i64 %.66082, i32 32)\n  %.5.i23 = getelementptr i8, i8* %.66091, i64 24\n  %48 = bitcast i8* %.5.i23 to double**\n  %.6.i244053 = load double*, double** %48, align 8\n  %.661632719 = icmp sgt i64 %.65990, 0\n  br i1 %.661632719, label %for.body.1113.us.preheader, label %for.body.1113.preheader4222\n\nfor.body.1113.us.preheader:                       ; preds = %for.body.1113.preheader\n  %49 = shl i64 %.65990, 3\n  br label %for.body.1113.us\n\nfor.body.1113.preheader4222:                      ; preds = %for.body.1113.preheader\n  %50 = bitcast i8* %.5.i211 to { i64, i64, i8, { i8*, i8* } }**\n  %.6.i204071.pre = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %50, align 8\n  %.66141.phi.trans.insert4282 = bitcast { i64, i64, i8, { i8*, i8* } }* %.6.i204071.pre to i64*\n  %.66142.pre = load i64, i64* %.66141.phi.trans.insert4282, align 8\n  br label %for.body.1113\n\nfor.body.1113.us:                                 ; preds = %for.body.1113.us.preheader, %for.end.1114.loopexit.us\n  %lsr.iv = phi double* [ %.6.i244053, %for.body.1113.us.preheader ], [ %54, %for.end.1114.loopexit.us ]\n  %loop.index.11132722.us = phi i64 [ %.66209.us, %for.end.1114.loopexit.us ], [ 0, %for.body.1113.us.preheader ]\n  %51 = bitcast i8* %.5.i211 to { i64, i64, i8, { i8*, i8* } }**\n  %.6.i204071.us = load { i64, i64, i8, { i8*, i8* } }*, { i64, i64, i8, { i8*, i8* } }** %51, align 8\n  %.66141.us4283 = bitcast { i64, i64, i8, { i8*, i8* } }* %.6.i204071.us to i64*\n  %.66142.us = load i64, i64* %.66141.us4283, align 8\n  %.66143.us = icmp slt i64 %loop.index.11132722.us, %.66142.us\n  br i1 %.66143.us, label %for.body.1113.endif.us, label %for.body.1113.if, !prof !2\n\nfor.body.1113.endif.us:                           ; preds = %for.body.1113.us\n  %.66155.us = getelementptr inbounds { i64, i64, i8, { i8*, i8* } }, { i64, i64, i8, { i8*, i8* } }* %.6.i204071.us, i64 0, i32 3\n  %.66157.elt.us = getelementptr { i8*, i8* }, { i8*, i8* }* %.66155.us, i64 %loop.index.11132722.us, i32 0\n  %.66157.unpack.us = load i8*, i8** %.66157.elt.us, align 8\n  br label %for.body.1114.us\n\nfor.body.1114.us:                                 ; preds = %for.body.1114.endif.us, %for.body.1113.endif.us\n  %loop.index.11142720.us = phi i64 [ %.66207.us, %for.body.1114.endif.us ], [ 0, %for.body.1113.endif.us ]\n  %sunkaddr = getelementptr i8, i8* %.66157.unpack.us, i64 24\n  %52 = bitcast i8* %sunkaddr to { i64, i64, i8, double }**\n  %.6.i24077.us = load { i64, i64, i8, double }*, { i64, i64, i8, double }** %52, align 8\n  %.66183.us4284 = bitcast { i64, i64, i8, double }* %.6.i24077.us to i64*\n  %.66184.us = load i64, i64* %.66183.us4284, align 8\n  %.66185.us = icmp slt i64 %loop.index.11142720.us, %.66184.us\n  br i1 %.66185.us, label %for.body.1114.endif.us, label %for.body.1114.if, !prof !2\n\nfor.body.1114.endif.us:                           ; preds = %for.body.1114.us\n  %scevgep4239 = getelementptr { i64, i64, i8, double }, { i64, i64, i8, double }* %.6.i24077.us, i64 0, i32 3\n  %scevgep4240 = getelementptr double, double* %scevgep4239, i64 %loop.index.11142720.us\n  %scevgep42404241 = bitcast double* %scevgep4240 to i64*\n  %.661994079.us = load i64, i64* %scevgep42404241, align 8\n  %scevgep4237 = getelementptr double, double* %lsr.iv, i64 %loop.index.11142720.us\n  %scevgep42374238 = bitcast double* %scevgep4237 to i64*\n  store i64 %.661994079.us, i64* %scevgep42374238, align 8\n  %.66207.us = add nuw nsw i64 %loop.index.11142720.us, 1\n  %exitcond = icmp eq i64 %.65990, %.66207.us\n  br i1 %exitcond, label %for.end.1114.loopexit.us, label %for.body.1114.us\n\nfor.end.1114.loopexit.us:                         ; preds = %for.body.1114.endif.us\n  %53 = bitcast double* %lsr.iv to i1*\n  %.66209.us = add nuw nsw i64 %loop.index.11132722.us, 1\n  %scevgep = getelementptr i1, i1* %53, i64 %49\n  %54 = bitcast i1* %scevgep to double*\n  %exitcond4225 = icmp eq i64 %.66209.us, %.65941\n  br i1 %exitcond4225, label %for.end.1113, label %for.body.1113.us\n\nfor.body.1113:                                    ; preds = %for.body.1113.endif, %for.body.1113.preheader4222\n  %loop.index.11132722 = phi i64 [ %.66209, %for.body.1113.endif ], [ 0, %for.body.1113.preheader4222 ]\n  %.66143 = icmp slt i64 %loop.index.11132722, %.66142.pre\n  br i1 %.66143, label %for.body.1113.endif, label %for.body.1113.if, !prof !2\n\nfor.end.1113:                                     ; preds = %for.body.1113.endif, %for.end.1114.loopexit.us\n  %retptr.repack4285 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %retptr to i8**\n  store i8* %.66091, i8** %retptr.repack4285, align 8\n  %retptr.repack4054 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 1\n  store i8* null, i8** %retptr.repack4054, align 8\n  %retptr.repack4056 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 2\n  store i64 %.66077, i64* %retptr.repack4056, align 8\n  %retptr.repack4058 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 3\n  store i64 8, i64* %retptr.repack4058, align 8\n  %retptr.repack4060 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 4\n  store double* %.6.i244053, double** %retptr.repack4060, align 8\n  %retptr.repack4062.repack = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 5, i64 0\n  store i64 %.65941, i64* %retptr.repack4062.repack, align 8\n  %retptr.repack4062.repack4068 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 5, i64 1\n  store i64 %.65990, i64* %retptr.repack4062.repack4068, align 8\n  %retptr.repack4064.repack = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 6, i64 0\n  store i64 %.66080, i64* %retptr.repack4064.repack, align 8\n  %retptr.repack4064.repack4066 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 6, i64 1\n  store i64 8, i64* %retptr.repack4064.repack4066, align 8\n  tail call void @NRT_decref(i8* nonnull %.65537)\n  ret i32 0\n\nfor.body.1113.if:                                 ; preds = %for.body.1113, %for.body.1113.us\n  store { i8*, i32, i8* }* @.const.picklebuf.1904697620984, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n\nfor.body.1113.endif:                              ; preds = %for.body.1113\n  %.66209 = add nuw nsw i64 %loop.index.11132722, 1\n  %exitcond4226 = icmp eq i64 %.65941, %.66209\n  br i1 %exitcond4226, label %for.end.1113, label %for.body.1113\n\nfor.body.1114.if:                                 ; preds = %for.body.1114.us\n  store { i8*, i32, i8* }* @.const.picklebuf.1904697620984, { i8*, i32, i8* }** %excinfo, align 8\n  ret i32 1, !ret_is_raise !1\n}\n\n; Function Attrs: nounwind readnone speculatable willreturn\ndeclare double @llvm.sin.f64(double) #0\n\n; Function Attrs: nounwind readnone speculatable willreturn\ndeclare double @llvm.cos.f64(double) #0\n\ndefine linkonce_odr void @.dtor.list.float64(i8* %.1) {\n.3:\n  ret void\n}\n\ndeclare i8* @NRT_MemInfo_new_varsize_dtor(i64, i8*) local_unnamed_addr\n\n; Function Attrs: argmemonly nounwind willreturn\ndeclare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1\n\ndefine linkonce_odr void @".dtor.list.list(float64)<iv=None>"(i8* %.1) {\n.3:\n  %.5 = bitcast i8* %.1 to i64*\n  %.8 = load i64, i64* %.5, align 8\n  %.101 = icmp sgt i64 %.8, 0\n  br i1 %.101, label %for.body.preheader, label %for.end\n\nfor.body.preheader:                               ; preds = %.3\n  %.12 = getelementptr inbounds i8, i8* %.1, i64 24\n  br label %for.body\n\nfor.body:                                         ; preds = %for.body, %for.body.preheader\n  %lsr.iv8 = phi i64 [ %lsr.iv.next, %for.body ], [ %.8, %for.body.preheader ]\n  %lsr.iv = phi i8* [ %scevgep, %for.body ], [ %.12, %for.body.preheader ]\n  %lsr.iv7 = bitcast i8* %lsr.iv to i8**\n  %.14.unpack = load i8*, i8** %lsr.iv7, align 8\n  tail call void @NRT_decref(i8* %.14.unpack)\n  %scevgep = getelementptr i8, i8* %lsr.iv, i64 16\n  %lsr.iv.next = add i64 %lsr.iv8, -1\n  %exitcond = icmp eq i64 %lsr.iv.next, 0\n  br i1 %exitcond, label %for.end, label %for.body\n\nfor.end:                                          ; preds = %for.body, %.3\n  ret void\n}\n\n; Function Attrs: nounwind readnone speculatable willreturn\ndeclare { i64, i1 } @llvm.smul.with.overflow.i64(i64, i64) #0\n\ndeclare noalias i8* @NRT_MemInfo_alloc_safe_aligned(i64, i32) local_unnamed_addr\n\ndefine i8* @"_ZN7cpython8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE"(i8* nocapture readnone %py_closure, i8* %py_args, i8* nocapture readnone %py_kws) local_unnamed_addr {\nentry:\n  %.5 = alloca i8*, align 8\n  %.6 = call i32 (i8*, i8*, i64, i64, ...) @PyArg_UnpackTuple(i8* %py_args, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.const.res, i64 0, i64 0), i64 1, i64 1, i8** nonnull %.5)\n  %.7 = icmp eq i32 %.6, 0\n  %.21 = alloca { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, align 8\n  %.43 = alloca { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, align 8\n  %0 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.21 to i8*\n  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(56) %0, i8 0, i64 56, i1 false)\n  %excinfo = alloca { i8*, i32, i8* }*, align 8\n  %1 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.43 to i8*\n  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(72) %1, i8 0, i64 72, i1 false)\n  store { i8*, i32, i8* }* null, { i8*, i32, i8* }** %excinfo, align 8\n  %.99 = alloca { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, align 8\n  %2 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.99 to i8*\n  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(72) %2, i8 0, i64 72, i1 false)\n  br i1 %.7, label %entry.if, label %entry.endif, !prof !0\n\nentry.if:                                         ; preds = %entry.endif.endif.if, %entry.endif.endif.endif.endif.endif.if, %entry.endif.endif.endif.endif.endif.endif, %entry.endif.endif.endif.endif.endif.if.if, %entry.endif.endif.endif.endif.endif.endif.if, %entry.endif.endif.endif.endif.endif.endif.endif.endif, %entry\n  ret i8* null\n\nentry.endif:                                      ; preds = %entry\n  %.11 = load i8*, i8** @"_ZN08NumbaEnv8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE", align 8\n  %.16 = icmp eq i8* %.11, null\n  br i1 %.16, label %entry.endif.if, label %entry.endif.endif, !prof !0\n\nentry.endif.if:                                   ; preds = %entry.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_RuntimeError, i8* getelementptr inbounds ([84 x i8], [84 x i8]* @".const.missing Environment: _ZN08NumbaEnv8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE", i64 0, i64 0))\n  ret i8* null\n\nentry.endif.endif:                                ; preds = %entry.endif\n  %.20 = load i8*, i8** %.5, align 8\n  %.24 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.21 to i8*\n  %3 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.21 to i8*\n  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(56) %3, i8 0, i64 56, i1 false)\n  %.25 = call i32 @NRT_adapt_ndarray_from_python(i8* %.20, i8* nonnull %.24)\n  %4 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.21 to i8*\n  %sunkaddr = getelementptr inbounds i8, i8* %4, i64 24\n  %5 = bitcast i8* %sunkaddr to i64*\n  %.29 = load i64, i64* %5, align 8\n  %.30 = icmp ne i64 %.29, 8\n  %.31 = icmp ne i32 %.25, 0\n  %.32 = or i1 %.31, %.30\n  br i1 %.32, label %entry.endif.endif.if, label %entry.endif.endif.endif.endif, !prof !0\n\nentry.endif.endif.if:                             ; preds = %entry.endif.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_TypeError, i8* getelementptr inbounds ([89 x i8], [89 x i8]* @".const.can\'t unbox array from PyObject into native value.  The object maybe of a different type", i64 0, i64 0))\n  br label %entry.if\n\nentry.endif.endif.endif.endif:                    ; preds = %entry.endif.endif\n  %6 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.43 to i8**\n  %7 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.21 to i8**\n  %.36.fca.0.load = load i8*, i8** %7, align 8\n  %8 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.21 to i8*\n  %sunkaddr6 = getelementptr inbounds i8, i8* %8, i64 32\n  %9 = bitcast i8* %sunkaddr6 to double**\n  %.36.fca.4.load = load double*, double** %9, align 8\n  %10 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.21 to i8*\n  %sunkaddr7 = getelementptr inbounds i8, i8* %10, i64 48\n  %11 = bitcast i8* %sunkaddr7 to i64*\n  %.36.fca.6.0.load = load i64, i64* %11, align 8\n  %12 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.43 to i8*\n  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(72) %12, i8 0, i64 72, i1 false)\n  %.49 = call i32 @"_ZN8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE"({ i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* nonnull %.43, { i8*, i32, i8* }** nonnull %excinfo, i8* undef, i8* undef, i64 undef, i64 undef, double* %.36.fca.4.load, i64 undef, i64 %.36.fca.6.0.load) #2\n  %.50 = load { i8*, i32, i8* }*, { i8*, i32, i8* }** %excinfo, align 8\n  %.59.fca.0.load = load i8*, i8** %6, align 8\n  %13 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.43 to i8*\n  %sunkaddr8 = getelementptr inbounds i8, i8* %13, i64 8\n  %14 = bitcast i8* %sunkaddr8 to <4 x i64>*\n  %15 = load <4 x i64>, <4 x i64>* %14, align 8\n  %16 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.43 to i8*\n  %sunkaddr9 = getelementptr inbounds i8, i8* %16, i64 40\n  %17 = bitcast i8* %sunkaddr9 to <4 x i64>*\n  %18 = load <4 x i64>, <4 x i64>* %17, align 8\n  call void @NRT_decref(i8* %.36.fca.0.load)\n  switch i32 %.49, label %entry.endif.endif.endif.endif.endif [\n    i32 -2, label %entry.endif.endif.endif.endif.if.if\n    i32 0, label %entry.endif.endif.endif.endif.if.endif\n  ]\n\nentry.endif.endif.endif.endif.endif:              ; preds = %entry.endif.endif.endif.endif\n  %.57 = icmp sgt i32 %.49, 0\n  br i1 %.57, label %entry.endif.endif.endif.endif.endif.if, label %entry.endif.endif.endif.endif.endif.endif\n\nentry.endif.endif.endif.endif.if.if:              ; preds = %entry.endif.endif.endif.endif\n  call void @Py_IncRef(i8* nonnull @_Py_NoneStruct)\n  ret i8* @_Py_NoneStruct\n\nentry.endif.endif.endif.endif.if.endif:           ; preds = %entry.endif.endif.endif.endif\n  %sunkaddr10 = getelementptr i8, i8* %.11, i64 24\n  %19 = bitcast i8* %sunkaddr10 to i8**\n  %.87 = load i8*, i8** %19, align 8\n  %.91 = icmp eq i8* %.87, null\n  br i1 %.91, label %entry.endif.endif.endif.endif.if.endif.else, label %entry.endif.endif.endif.endif.if.endif.if\n\nentry.endif.endif.endif.endif.if.endif.if:        ; preds = %entry.endif.endif.endif.endif.if.endif\n  %.93 = call i8* @PyList_GetItem(i8* nonnull %.87, i64 0)\n  br label %entry.endif.endif.endif.endif.if.endif.endif\n\nentry.endif.endif.endif.endif.if.endif.else:      ; preds = %entry.endif.endif.endif.endif.if.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_RuntimeError, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @".const.`env.consts` is NULL in `read_const`", i64 0, i64 0))\n  br label %entry.endif.endif.endif.endif.if.endif.endif\n\nentry.endif.endif.endif.endif.if.endif.endif:     ; preds = %entry.endif.endif.endif.endif.if.endif.else, %entry.endif.endif.endif.endif.if.endif.if\n  %.88.0 = phi i8* [ %.93, %entry.endif.endif.endif.endif.if.endif.if ], [ null, %entry.endif.endif.endif.endif.if.endif.else ]\n  %20 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.99 to i8**\n  store i8* %.59.fca.0.load, i8** %20, align 8\n  %21 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.99 to i8*\n  %sunkaddr11 = getelementptr inbounds i8, i8* %21, i64 8\n  %22 = bitcast i8* %sunkaddr11 to <4 x i64>*\n  store <4 x i64> %15, <4 x i64>* %22, align 8\n  %23 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.99 to i8*\n  %sunkaddr12 = getelementptr inbounds i8, i8* %23, i64 40\n  %24 = bitcast i8* %sunkaddr12 to <4 x i64>*\n  store <4 x i64> %18, <4 x i64>* %24, align 8\n  %.102 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.99 to i8*\n  %.103 = call i8* @NRT_adapt_ndarray_to_python_acqref(i8* nonnull %.102, i32 2, i32 1, i8* %.88.0)\n  call void @NRT_decref(i8* %.59.fca.0.load)\n  ret i8* %.103\n\nentry.endif.endif.endif.endif.endif.if:           ; preds = %entry.endif.endif.endif.endif.endif\n  call void @PyErr_Clear()\n  %.113 = load { i8*, i32, i8* }, { i8*, i32, i8* }* %.50, align 8\n  %.114 = extractvalue { i8*, i32, i8* } %.113, 0\n  %.116 = extractvalue { i8*, i32, i8* } %.113, 1\n  %.118 = extractvalue { i8*, i32, i8* } %.113, 2\n  %.119 = call i8* @numba_unpickle(i8* %.114, i32 %.116, i8* %.118)\n  %.120 = icmp eq i8* %.119, null\n  br i1 %.120, label %entry.if, label %entry.endif.endif.endif.endif.endif.if.if, !prof !0\n\nentry.endif.endif.endif.endif.endif.endif:        ; preds = %entry.endif.endif.endif.endif.endif\n  switch i32 %.49, label %entry.endif.endif.endif.endif.endif.endif.endif.endif [\n    i32 -3, label %entry.endif.endif.endif.endif.endif.endif.if\n    i32 -1, label %entry.if\n  ]\n\nentry.endif.endif.endif.endif.endif.if.if:        ; preds = %entry.endif.endif.endif.endif.endif.if\n  call void @numba_do_raise(i8* nonnull %.119)\n  br label %entry.if\n\nentry.endif.endif.endif.endif.endif.endif.if:     ; preds = %entry.endif.endif.endif.endif.endif.endif\n  call void @PyErr_SetNone(i8* nonnull @PyExc_StopIteration)\n  br label %entry.if\n\nentry.endif.endif.endif.endif.endif.endif.endif.endif: ; preds = %entry.endif.endif.endif.endif.endif.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_SystemError, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @".const.unknown error when calling native function", i64 0, i64 0))\n  br label %entry.if\n}\n\ndeclare i32 @PyArg_UnpackTuple(i8*, i8*, i64, i64, ...) local_unnamed_addr\n\ndeclare void @PyErr_SetString(i8*, i8*) local_unnamed_addr\n\ndeclare i32 @NRT_adapt_ndarray_from_python(i8* nocapture, i8* nocapture) local_unnamed_addr\n\ndeclare void @Py_IncRef(i8*) local_unnamed_addr\n\ndeclare i8* @PyList_GetItem(i8*, i64) local_unnamed_addr\n\ndeclare i8* @NRT_adapt_ndarray_to_python_acqref(i8* nocapture, i32, i32, i8*) local_unnamed_addr\n\ndeclare void @PyErr_Clear() local_unnamed_addr\n\ndeclare i8* @numba_unpickle(i8*, i32, i8*) local_unnamed_addr\n\ndeclare void @numba_do_raise(i8*) local_unnamed_addr\n\ndeclare void @PyErr_SetNone(i8*) local_unnamed_addr\n\ndefine { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] } @"cfunc._ZN8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE"({ i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.1) local_unnamed_addr {\nentry:\n  %.3 = alloca { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, align 8\n  %.fca.0.gep1 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3 to i8**\n  %.fca.1.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3, i64 0, i32 1\n  %.fca.2.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3, i64 0, i32 2\n  %.fca.3.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3, i64 0, i32 3\n  %.fca.4.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3, i64 0, i32 4\n  %.fca.5.0.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3, i64 0, i32 5, i64 0\n  %.fca.5.1.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3, i64 0, i32 5, i64 1\n  %.fca.6.0.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3, i64 0, i32 6, i64 0\n  %.fca.6.1.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3, i64 0, i32 6, i64 1\n  %excinfo = alloca { i8*, i32, i8* }*, align 8\n  %0 = bitcast { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* %.3 to i8*\n  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(72) %0, i8 0, i64 72, i1 false)\n  store { i8*, i32, i8* }* null, { i8*, i32, i8* }** %excinfo, align 8\n  %extracted.data = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.1, 4\n  %extracted.strides = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.1, 6\n  %.8 = extractvalue [1 x i64] %extracted.strides, 0\n  %.9 = call i32 @"_ZN8__main__7res$244E5ArrayIdLi1E1A7mutable7alignedE"({ i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] }* nonnull %.3, { i8*, i32, i8* }** nonnull %excinfo, i8* undef, i8* undef, i64 undef, i64 undef, double* %extracted.data, i64 undef, i64 %.8) #2\n  %.10 = load { i8*, i32, i8* }*, { i8*, i32, i8* }** %excinfo, align 8\n  %.19.fca.0.load = load i8*, i8** %.fca.0.gep1, align 8\n  %.19.fca.0.insert = insertvalue { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] } undef, i8* %.19.fca.0.load, 0\n  %.19.fca.1.load = load i8*, i8** %.fca.1.gep, align 8\n  %.19.fca.1.insert = insertvalue { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] } %.19.fca.0.insert, i8* %.19.fca.1.load, 1\n  %.19.fca.2.load = load i64, i64* %.fca.2.gep, align 8\n  %.19.fca.2.insert = insertvalue { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] } %.19.fca.1.insert, i64 %.19.fca.2.load, 2\n  %.19.fca.3.load = load i64, i64* %.fca.3.gep, align 8\n  %.19.fca.3.insert = insertvalue { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] } %.19.fca.2.insert, i64 %.19.fca.3.load, 3\n  %.19.fca.4.load = load double*, double** %.fca.4.gep, align 8\n  %.19.fca.4.insert = insertvalue { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] } %.19.fca.3.insert, double* %.19.fca.4.load, 4\n  %.19.fca.5.0.load = load i64, i64* %.fca.5.0.gep, align 8\n  %.19.fca.5.1.load = load i64, i64* %.fca.5.1.gep, align 8\n  %.19.fca.6.0.load = load i64, i64* %.fca.6.0.gep, align 8\n  %.19.fca.6.1.load = load i64, i64* %.fca.6.1.gep, align 8\n  %1 = insertvalue [2 x i64] undef, i64 %.19.fca.5.0.load, 0\n  %.25 = insertvalue [2 x i64] %1, i64 %.19.fca.5.1.load, 1\n  %2 = insertvalue [2 x i64] undef, i64 %.19.fca.6.0.load, 0\n  %.26 = insertvalue [2 x i64] %2, i64 %.19.fca.6.1.load, 1\n  %inserted.shape = insertvalue { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] } %.19.fca.4.insert, [2 x i64] %.25, 5\n  %inserted.strides = insertvalue { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] } %inserted.shape, [2 x i64] %.26, 6\n  %.36 = alloca i32, align 4\n  store i32 0, i32* %.36, align 4\n  switch i32 %.9, label %entry.if [\n    i32 -2, label %entry.endif\n    i32 0, label %entry.endif\n  ]\n\nentry.if:                                         ; preds = %entry\n  %.17 = icmp sgt i32 %.9, 0\n  call void @numba_gil_ensure(i32* nonnull %.36)\n  br i1 %.17, label %entry.if.if, label %entry.if.endif\n\nentry.endif:                                      ; preds = %entry, %entry, %.39\n  ret { i8*, i8*, i64, i64, double*, [2 x i64], [2 x i64] } %inserted.strides\n\n.39:                                              ; preds = %entry.if.if, %entry.if.endif, %entry.if.if.if, %entry.if.endif.endif.endif, %entry.if.endif.if\n  %.61 = call i8* @PyUnicode_FromString(i8* getelementptr inbounds ([57 x i8], [57 x i8]* @".const.<numba.core.cpu.CPUContext object at 0x000001BB633C69C8>", i64 0, i64 0))\n  call void @PyErr_WriteUnraisable(i8* %.61)\n  call void @Py_DecRef(i8* %.61)\n  call void @numba_gil_release(i32* nonnull %.36)\n  br label %entry.endif\n\nentry.if.if:                                      ; preds = %entry.if\n  call void @PyErr_Clear()\n  %.42 = load { i8*, i32, i8* }, { i8*, i32, i8* }* %.10, align 8\n  %.43 = extractvalue { i8*, i32, i8* } %.42, 0\n  %.45 = extractvalue { i8*, i32, i8* } %.42, 1\n  %.47 = extractvalue { i8*, i32, i8* } %.42, 2\n  %.48 = call i8* @numba_unpickle(i8* %.43, i32 %.45, i8* %.47)\n  %.49 = icmp eq i8* %.48, null\n  br i1 %.49, label %.39, label %entry.if.if.if, !prof !0\n\nentry.if.endif:                                   ; preds = %entry.if\n  switch i32 %.9, label %entry.if.endif.endif.endif [\n    i32 -3, label %entry.if.endif.if\n    i32 -1, label %.39\n  ]\n\nentry.if.if.if:                                   ; preds = %entry.if.if\n  call void @numba_do_raise(i8* nonnull %.48)\n  br label %.39\n\nentry.if.endif.if:                                ; preds = %entry.if.endif\n  call void @PyErr_SetNone(i8* nonnull @PyExc_StopIteration)\n  br label %.39\n\nentry.if.endif.endif.endif:                       ; preds = %entry.if.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_SystemError, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @".const.unknown error when calling native function.1", i64 0, i64 0))\n  br label %.39\n}\n\ndeclare void @numba_gil_ensure(i32*) local_unnamed_addr\n\ndeclare i8* @PyUnicode_FromString(i8*) local_unnamed_addr\n\ndeclare void @PyErr_WriteUnraisable(i8*) local_unnamed_addr\n\ndeclare void @Py_DecRef(i8*) local_unnamed_addr\n\ndeclare void @numba_gil_release(i32*) local_unnamed_addr\n\n; Function Attrs: noinline\ndefine linkonce_odr void @NRT_decref(i8* %.1) local_unnamed_addr #2 {\n.3:\n  %.4 = icmp eq i8* %.1, null\n  br i1 %.4, label %.3.if, label %.3.endif, !prof !0\n\n.3.if:                                            ; preds = %.3.endif, %.3\n  ret void\n\n.3.endif:                                         ; preds = %.3\n  fence release\n  %.8 = bitcast i8* %.1 to i64*\n  %.4.i = atomicrmw sub i64* %.8, i64 1 monotonic\n  %.10 = icmp eq i64 %.4.i, 1\n  br i1 %.10, label %.3.endif.if, label %.3.if, !prof !0\n\n.3.endif.if:                                      ; preds = %.3.endif\n  fence acquire\n  tail call void @NRT_MemInfo_call_dtor(i8* nonnull %.1)\n  ret void\n}\n\ndeclare void @NRT_MemInfo_call_dtor(i8*) local_unnamed_addr\n\n; Function Attrs: nounwind\ndeclare void @llvm.stackprotector(i8*, i8**) #3\n\nattributes #0 = { nounwind readnone speculatable willreturn }\nattributes #1 = { argmemonly nounwind willreturn }\nattributes #2 = { noinline }\nattributes #3 = { nounwind }\n\n!0 = !{!"branch_weights", i32 1, i32 99}\n!1 = !{i1 true}\n!2 = !{!"branch_weights", i32 99, i32 1}\n'}